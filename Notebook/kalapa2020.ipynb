{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"kalapa2020.ipynb","provenance":[{"file_id":"1kzcFJomC86e7NTNdcPtjbwyXEPLZZcxd","timestamp":1598266850913}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hlEc63FgB3J7","executionInfo":{"status":"ok","timestamp":1600467492495,"user_tz":-420,"elapsed":23076,"user":{"displayName":"Trần Quốc Khánh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVFfhxvf9yjuqauX7S1hOIYkYyKbpLDYlcZz-=s64","userId":"04381164842406200205"}},"outputId":"4a924b6b-e5a3-457b-ffde-a19a1f7375ae","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"knKEjEEYIRDH","executionInfo":{"status":"ok","timestamp":1600467495316,"user_tz":-420,"elapsed":1324,"user":{"displayName":"Trần Quốc Khánh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVFfhxvf9yjuqauX7S1hOIYkYyKbpLDYlcZz-=s64","userId":"04381164842406200205"}},"outputId":"6485d3d2-ebfd-4f29-e2f4-aec51aaf9e4e","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/kalapa"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/kalapa\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"om6YQ3fKCGec","executionInfo":{"status":"ok","timestamp":1600467510533,"user_tz":-420,"elapsed":14474,"user":{"displayName":"Trần Quốc Khánh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVFfhxvf9yjuqauX7S1hOIYkYyKbpLDYlcZz-=s64","userId":"04381164842406200205"}},"outputId":"c198f8e8-616f-48fd-adee-584dcea528c5","colab":{"base_uri":"https://localhost:8080/","height":700}},"source":["!pip install feature_engine\n","!pip install unidecode\n","!pip install category_encoders"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting feature_engine\n","  Downloading https://files.pythonhosted.org/packages/d3/36/651f586a52495f6eba6613eafb6e9238a259fd78ece78b03486042a0ff71/feature_engine-0.6.0-py2.py3-none-any.whl\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (1.4.1)\n","Collecting statsmodels>=0.11.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/93/1b6882f92d94e491a3e3be101fc83934551eada261281980f3957246432f/statsmodels-0.12.0-cp36-cp36m-manylinux1_x86_64.whl (9.5MB)\n","\u001b[K     |████████████████████████████████| 9.5MB 4.8MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (1.0.5)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (1.18.5)\n","Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (0.22.2.post1)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.1)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.3->feature_engine) (2018.9)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.2->feature_engine) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5->statsmodels>=0.11.1->feature_engine) (1.15.0)\n","Installing collected packages: statsmodels, feature-engine\n","  Found existing installation: statsmodels 0.10.2\n","    Uninstalling statsmodels-0.10.2:\n","      Successfully uninstalled statsmodels-0.10.2\n","Successfully installed feature-engine-0.6.0 statsmodels-0.12.0\n","Collecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\u001b[K     |████████████████████████████████| 245kB 2.8MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.1.1\n","Collecting category_encoders\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n","\u001b[K     |████████████████████████████████| 81kB 2.3MB/s \n","\u001b[?25hRequirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.12.0)\n","Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.0.5)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.5)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n","Installing collected packages: category-encoders\n","Successfully installed category-encoders-2.2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lH7hco0wCZV_"},"source":["from itertools import combinations\n","\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import math\n","import re\n","import warnings\n","\n","import lightgbm as lgb\n","from unidecode import unidecode\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","from feature_engine import categorical_encoders as ce\n","\n","from datetime import datetime\n","from contextlib import contextmanager"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2juOrYmYRd89"},"source":["lgbm_param = {'boosting_type': 'gbdt', \n","              'metric': 'auc',\n","              #'colsample_bytree': 0.6602479798930369, \n","              'is_unbalance': False, \n","              'learning_rate': 0.01,\n","              'max_depth': -1, \n","              'min_split_gain': 0.007, \n","              'min_child_samples': 25, \n","              'num_leaves': 50,\n","              'objective': 'binary', \n","              'reg_alpha': 0.4693391197064131, \n","              'reg_lambda': 0.16175478669541327, \n","              'subsample_for_bin': 60000}\n","\n","NUM_BOOST_ROUND= 10000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M6vLutkQCggr"},"source":["DROP = ([\"gioiTinh\",\"info_social_sex\", 'currentLocationLocationId', 'currentLocationLatitude', 'currentLocationLongitude', 'homeTownLocationId', 'homeTownLatitude', 'homeTownLongitude', 'currentLocationName', 'homeTownName'] + \n","[f\"Field_{c}\" for c in [11, 13, 14, 15, 16, 17, 18, 24, 25, 26, 30, 31, 32, 33, 34, 35, 37, 40, 45, 46, 48, 49, 52, 56, 57, 68]] + \n","['partner0_B', 'partner0_K', 'partner0_L', 'partner1_B', 'partner1_D', 'partner1_E', 'partner1_F', 'partner1_K', 'partner1_L', \n","   'partner2_B', 'partner2_G', 'partner2_K', 'partner2_L', \n","   'partner3_B', 'partner3_C', 'partner3_F', 'partner3_G', 'partner3_H', 'partner3_K', 'partner3_L', \n","   'partner4_A', 'partner4_B', 'partner4_C', 'partner4_D', 'partner4_E', 'partner4_F', 'partner4_G', 'partner4_H', 'partner4_K', 'partner4_L', \n","   'partner5_B', 'partner5_C', 'partner5_D', 'partner5_H', 'partner5_K', 'partner5_L'])\n","\n","cat_features_count_encode = ['Field_4', 'Field_12', 'Field_18', 'Field_34', 'gioiTinh', 'diaChi', 'Field_36',\n","                             'Field_38', 'Field_45', 'Field_46', 'Field_47', 'Field_48', 'Field_49',\n","                             'Field_54', 'Field_55', 'Field_56', 'Field_61', 'Field_62', 'Field_65', 'Field_66',\n","                             'Field_68', 'maCv', 'info_social_sex', 'data.basic_info.locale',\n","                             'currentLocationCountry', 'currentLocationState', 'homeTownCountry', 'homeTownState', 'brief']\n","\n","unidecode_columns = 'diaChi currentLocationCountry currentLocationState homeTownCountry homeTownState maCv'.split()\n","DATE = [\"Field_{}\".format(i) for i in [5, 6, 7, 8, 9, 11, 15, 25, 32, 33, 34, 35, 40]]\n","DATETIME = [\"Field_{}\".format(i) for i in [1, 2, 43, 44]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8x2nkMuwRyJs"},"source":["from sklearn.ensemble import RandomForestClassifier\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T2bob6S0RbaV","executionInfo":{"status":"ok","timestamp":1600467527860,"user_tz":-420,"elapsed":978,"user":{"displayName":"Trần Quốc Khánh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVFfhxvf9yjuqauX7S1hOIYkYyKbpLDYlcZz-=s64","userId":"04381164842406200205"}},"outputId":"7a80d463-1a0f-4443-84db-4cebe6a7e5f9","colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n","            max_depth=None, max_features='auto', max_leaf_nodes=None,\n","            min_impurity_decrease=0.0, min_impurity_split=None,\n","            min_samples_leaf=1, min_samples_split=2,\n","            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n","            oob_score=False, random_state=None, verbose=0,\n","            warm_start=False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n","                       oob_score=False, random_state=None, verbose=0,\n","                       warm_start=False)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"azUNtp6OCuSm"},"source":["@contextmanager\n","def timer(title):\n","    t0 = time.time()\n","    yield\n","    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n","\n","def Gini(y_true, y_pred):\n","    # check and get number of samples\n","    assert y_true.shape == y_pred.shape\n","    n_samples = y_true.shape[0]\n","\n","    # sort rows on prediction column\n","    # (from largest to smallest)\n","    arr = np.array([y_true, y_pred]).transpose()\n","    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n","    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n","\n","    # get Lorenz curves\n","    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n","    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n","    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n","\n","    # get Gini coefficients (area between curves)\n","    G_true = np.sum(L_ones - L_true)\n","    G_pred = np.sum(L_ones - L_pred)\n","\n","    # normalize to true Gini coefficient\n","    return G_pred * 1. / G_true\n","\n","def lgb_gini(y_pred, dataset_true):\n","    y_true = dataset_true.get_label()\n","    return 'gini', Gini(y_true, y_pred), True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCUl1Rz1C48M"},"source":["def subtract_date(date1,date2, df):\n","    df[date1] = pd.to_datetime(df[date1], infer_datetime_format=True)\n","    df[date2] = pd.to_datetime(df[date2], infer_datetime_format=True)\n","    df[date1+date2] = (df[date2] - df[date1]).dt.days\n","    \n","def process_ngaySinh(s):\n","    if s != s:\n","        return np.nan\n","    try:\n","        s = int(s)\n","    except ValueError:\n","        s = s.split(\" \")[0]\n","        \n","    return datetime.strptime(str(s)[:6], \"%Y%m\")\n","\n","def datetime_normalize(s):\n","    if s != s:\n","        return np.nan\n","        \n","    s = s.split(\".\")[0]\n","    if s[-1] == \"Z\":\n","        s = s[:-1]\n","        \n","    date, time = s.split(\"T\")\n","    datetime_obj = datetime.strptime(s, \"%Y-%m-%dT%H:%M:%S\")\n","    return datetime_obj\n","\n","def date_normalize(s):\n","    if s != s:\n","        return np.nan\n","    \n","    try:\n","        datetime_obj = datetime.strptime(s, \"%m/%d/%Y\")\n","    except:\n","        datetime_obj = datetime.strptime(s, \"%Y-%m-%d\")\n","        \n","    return datetime_obj\n","  \n","def process_datetime_cols(df):\n","    cat_cols = []\n","    for col in DATETIME:\n","        df[col] = df[col].apply(datetime_normalize)\n","        \n","    for col in DATE:\n","        if col == \"Field_34\":\n","            continue\n","        df[col] = df[col].apply(date_normalize)\n","\n","    df[\"Field_34\"] = df[\"Field_34\"].apply(process_ngaySinh)\n","    df[\"ngaySinh\"] = df[\"ngaySinh\"].apply(process_ngaySinh)\n","    \n","    cat_cols += DATE + DATETIME\n","    for col in DATE + DATETIME:\n","        #df[col].fillna(0)\n","        df[col] = df[col].dt.strftime('%m-%Y') #%d-%m-%Y\n","    \n","    subtract_date('Field_5','Field_6',df)\n","    subtrac_List = ['Field_1', 'Field_2', 'Field_43', 'Field_44', 'Field_7','Field_8', 'Field_9']\n","    subtract_2C = list(combinations(subtrac_List, 2))\n","    for l in subtract_2C:\n","        subtract_date(l[0],l[1],df)\n","      \n","    for cat in ['F', 'E', 'C', 'G', 'A']:\n","        subtract_date(f'{cat}_startDate', f'{cat}_endDate', df)\n","    for col in cat_cols:\n","        df[col] = df[col].astype(\"category\")\n","    print(df.shape) \n","    return df\n","  \n","def str_normalize(s):\n","    s = str(s).strip().lower()\n","    s = re.sub(' +', \" \", s)\n","    return s\n","\n","def process_location(df):\n","    for col in [\"currentLocationLocationId\", \"homeTownLocationId\", \"currentLocationLatitude\", \"currentLocationLongitude\", \n","                   \"homeTownLatitude\", \"homeTownLongitude\"]:\n","        df[col].replace(0, np.nan, inplace=True)\n","\n","    df[\"currentLocationLocationId\"] = df[\"currentLocationLocationId\"].apply(str_normalize).astype(\"category\")\n","    df[\"homeTownLocationId\"] = df[\"homeTownLocationId\"].apply(str_normalize).astype(\"category\")\n","\n","    return df\n","\n","def job_category(x):\n","    if type(x) == str:\n","        if \"công nhân\" in x or \"cnv\" in x or \"cn\" in x or \"may công nghiệp\" in x or \"lao động\" in x\\\n","        or \"thợ\" in x or \"coõng nhaõn trửùc tieỏp maựy may coõng nghieọp\" in x or \"c.n\" in x or \"lđ\" in x:\n","            return \"CN\"\n","        elif \"giáo viên\" in x or \"gv\" in x or \"gíao viên\" in x:\n","            return \"GV\"\n","        elif \"nhân viên\" in x or \"kế toán\" in x or \"cán bộ\" in x or \"nv\" in x or \"cb\" in x or \"nhõn viờn\" in x:\n","            return \"NV\"\n","        elif \"tài xế\" in x or \"lái\" in x or \"tài xê\" in x:\n","            return \"TX\"\n","        elif \"quản lý\" in x or \"phó phòng\" in x or \"hiệu phó\" in x:\n","            return \"QL\"\n","        elif \"undefined\" in x:\n","            return \"missing\"\n","        elif \"giám đốc\" in x or \"hiệu trưởng\" in x:\n","            return \"GĐ\"\n","        elif \"phục vụ\" in x:\n","            return \"PV\"\n","        elif \"chuyên viên\" in x:\n","            return  \"CV\"\n","        elif \"bác sĩ\" in x or \"dược sĩ\" in x or \"y sĩ\" in x or \"y sỹ\" in x:\n","            return \"BS\"\n","        elif \"y tá\" in x:\n","            return \"YT\"\n","        elif \"hộ sinh\" in x:\n","            return \"HS\"\n","        elif \"chủ tịch\" in x:\n","            return \"CT\"\n","        elif \"bếp\" in x:\n","            return \"ĐB\"\n","        elif \"sư\" in x:\n","            return \"KS\"\n","        elif \"dưỡng\" in x:\n","            return \"ĐD\"\n","        elif \"kỹ thuật\" in x or \"kĩ thuật\" in x:\n","            return \"KTV\"\n","        elif \"diễn viên\" in x:\n","            return \"DV\"\n","        else:\n","            return \"missing\"\n","    else:\n","        return x \n","\n","def process_diaChi_maCv(df):\n","    df[\"maCv\"] = df[\"maCv\"].apply(str_normalize).apply(job_category).astype(\"category\")\n","    return df\n","\n","def combine_gender(s):\n","    x, y = s\n","    if x != x and y != y:\n","        return \"nan\"\n","    \n","    if x != x:\n","        return y.lower()\n","    \n","    return x.lower()\n","\n","def process_gender(df):\n","    df[\"gender\"] = df[[\"gioiTinh\", \"info_social_sex\"]].apply(combine_gender, axis=1).astype(\"category\")\n","    return df\n","\n","def process_ordinal(df):\n","    print(df.columns)\n","\n","    df[\"subscriberCount\"].replace(0, np.nan, inplace=True)\n","    df[\"friendCount\"].replace(0, np.nan, inplace=True)\n","\n","    df[\"Field_13\"] = df[\"Field_13\"].apply(lambda x: 1 if x == x else 0)\n","    df[\"Field_38\"] = df[\"Field_38\"].map({0: 0.0, 1: 1.0, \"DN\": np.nan, \"TN\": np.nan, \"GD\": np.nan})\n","    df[\"Field_62\"] = df[\"Field_62\"].map({\"I\": 1.0, \"II\": 2.0, \"III\": 3.0, \"IV\": 4.0, \"V\": 5.0, \"Ngoài quốc doanh Quận 7\": np.nan})\n","    df[\"Field_47\"] = df[\"Field_47\"].map({\"Zezo\": 0.0, \"One\": 1.0, \"Two\": 2.0, \"Three\": 3.0, \"Four\": 4.0})\n","    df[\"Field_66\"] = df[\"Field_66\"].map({\"B\": 0.0, \"C\": 1.0, \"D\": 2.0, \"E\": 3.0, \"F\": 4.0, \"G\": 5.0, \"H\": 6.0, \"I\": 7.0})\n","\n","    df[\"Field_27\"] = df[\"Field_27\"].replace({0.0: np.nan})\n","    df[\"Field_28\"] = df[\"Field_28\"].replace({0.0: np.nan})\n","        \n","    for col in df.columns:\n","        if df[col].dtype.name == \"object\":\n","            df[col] = df[col].apply(str_normalize).astype(\"category\")\n","            \n","    return df\n","\n","def transform(df):\n","    df[\"gioiTinh\"] = df[\"gioiTinh\"].str.lower()\n","    df[\"maCv\"] = df[\"maCv\"].str.lower()\n","    df = process_datetime_cols(df)\n","    df = process_gender(df)\n","    df = process_location(df)\n","    df = process_diaChi_maCv(df)\n","    df = process_ordinal(df)\n","    #df[unidecode_columns] = df[unidecode_columns].applymap(lambda x: unidecode(x).lower() if x == x else x)\n","    #print(df[unidecode_columns])\n","    #df[cat_features_count_encode] = df[cat_features_count_encode].astype('category')\n","    df[\"null_sum\"] = df.isnull().sum(axis=1)\n","    return df.drop(DROP, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTrcMBbhMJqg"},"source":["def kfold(train_fe,y_label,test_fe):\n","    seeds = np.random.randint(0, 10000, 1)\n","    preds = 0    \n","    feature_important = None\n","    avg_train_gini = 0\n","    avg_val_gini = 0\n","\n","    for s in seeds:\n","        skf = StratifiedKFold(n_splits=5, random_state = 6484, shuffle=True)        \n","   \n","        seed_train_gini = 0\n","        seed_val_gini = 0\n","        for i, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(y_label)), y_label)):                \n","            X_train, X_val = train_fe.iloc[train_idx].drop([\"id\"], 1), train_fe.iloc[val_idx].drop([\"id\"], 1)                \n","            y_train, y_val = y_label[train_idx], y_label[val_idx]\n","\n","            lgb_train = lgb.Dataset(X_train, y_train)\n","            lgb_eval  = lgb.Dataset(X_val, y_val)\n","          \n","#Create a Gaussian Classifier\n","clf=RandomForestClassifier(n_estimators=100)\n","\n","#Train the model using the training sets y_pred=clf.predict(X_test)\n","clf.fit(X_train,y_train)\n","            evals_result = {}\n","            model = lgb.train(lgbm_param,\n","                        lgb_train,\n","                        num_boost_round=NUM_BOOST_ROUND,  \n","                        early_stopping_rounds=800,\n","                        feval=lgb_gini,\n","                        verbose_eval= 200,\n","                        evals_result=evals_result,\n","                        valid_sets=[lgb_train, lgb_eval])\n","\n","            seed_train_gini += model.best_score[\"training\"][\"gini\"] / skf.n_splits\n","            seed_val_gini += model.best_score[\"valid_1\"][\"gini\"] / skf.n_splits\n","\n","            avg_train_gini += model.best_score[\"training\"][\"gini\"] / (len(seeds) * skf.n_splits)\n","            avg_val_gini += model.best_score[\"valid_1\"][\"gini\"] / (len(seeds) * skf.n_splits)\n","\n","            if feature_important is None:\n","                feature_important = model.feature_importance() / (len(seeds) * skf.n_splits)\n","            else:\n","                feature_important += model.feature_importance() / (len(seeds) * skf.n_splits)        \n","\n","            pred = model.predict(test_fe.drop([\"id\"], 1))\n","            preds += pred / (skf.n_splits * len(seeds))\n","\n","            print(\"Fold {}: {}/{}\".format(i, model.best_score[\"training\"][\"gini\"], model.best_score[\"valid_1\"][\"gini\"]))  \n","        print(\"Seed {}: {}/{}\".format(s, seed_train_gini, seed_val_gini))\n","\n","    print(\"-\" * 50)\n","    print(\"Avg train gini: {}\".format(avg_train_gini))\n","    print(\"Avg valid gini: {}\".format(avg_val_gini))\n","    print(\"=\" * 50)\n","    return preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J6sRAY-xDih1","executionInfo":{"status":"ok","timestamp":1600377624336,"user_tz":-420,"elapsed":22352,"user":{"displayName":"Trần Quốc Khánh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVFfhxvf9yjuqauX7S1hOIYkYyKbpLDYlcZz-=s64","userId":"04381164842406200205"}},"outputId":"154ecf4b-4a9e-47f7-f14c-811dda7a31f1","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["df_train = pd.read_csv('/content/drive/My Drive/kalapa/dataset/train.csv')\n","df_test = pd.read_csv('/content/drive/My Drive/kalapa/dataset/test.csv')\n","df_all = df_train.drop(['label'], 1).append(df_test)\n","df_train.fillna(-1, inplace=True)\n","df_test.fillna(-1, inplace=True)\n","\n","df_all.replace(\"None\", -1, inplace=True)\n","df_all.replace(\"Missing\", -999, inplace=True)\n","df_all[\"gioiTinh\"] = df_train[\"gioiTinh\"].str.lower()\n","\n","with timer(\"Preprocess\"):\n","    df_all_fe = transform(df_all.copy())\n","    print(\"Bureau df shape:\", df_all_fe.shape)\n","    df_all_fe['Age'] = df_all_fe.ngaySinh.apply(lambda x: 2020 - x.year)\n","    df_all_fe = df_all_fe.drop('ngaySinh', axis = 1)\n","    cols_select = [x for x in df_all_fe.columns if x not in DATE + DATETIME  + [f'{cat}_endDate' for cat in ['F', 'E', 'C', 'G', 'A']] + [f'{cat}_startDate' for cat in ['F', 'E', 'C', 'G', 'A']]]\n","    df_fe = df_all_fe[cols_select]\n","    df_fe.replace([np.inf, -np.inf], -99999, inplace=True)\n","\n","    y_label = df_train[\"label\"]\n","    train_fe = df_fe[df_fe[\"id\"] < df_train.shape[0]]\n","    test_fe = df_fe[df_fe[\"id\"] >= df_train.shape[0]]\n","\n","    # Label-Encoding\n","    lbl = LabelEncoder()\n","    for col in df_fe.columns:\n","      if df_fe[col].dtype.name == \"category\":\n","        train_fe[col] = train_fe[col].astype(str)\n","        test_fe[col] = test_fe[col].astype(str)\n","        encoder = ce.CountFrequencyCategoricalEncoder(encoding_method='frequency')\n","        train_fe[col] = train_fe[col].fillna('None')\n","        test_fe[col] = test_fe[col].fillna('None')\n","\n","        # Only take the common values in Train/Test set\n","        common_vals = list(set(train_fe[col]).intersection(set(test_fe[col])))\n","\n","        # Take if vals appeared both 5 times\n","        common_vals = set(train_fe[col].value_counts()[train_fe[col].value_counts() > 4].index).intersection(test_fe[col].value_counts()[test_fe[col].value_counts()>4].index)\n","\n","        # Replace not-common values with \"Missing\" or np.nan\n","        train_fe.loc[~train_fe[col].isin(common_vals), col] = 'Missing'\n","        test_fe.loc[~test_fe[col].isin(common_vals), col] = 'Missing'\n","\n","        # Implement LE\n","        lbl.fit(train_fe[col].tolist() + test_fe[col].tolist())\n","        train_fe[col] = lbl.transform(train_fe[col])\n","        test_fe[col] = lbl.transform(test_fe[col])\n","\n","    print(train_fe.shape)\n","    print(test_fe.shape) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (35,43) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n","/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (34,42) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n"],"name":"stderr"},{"output_type":"stream","text":["(73411, 221)\n","Index(['id', 'Field_1', 'Field_2', 'Field_3', 'Field_4', 'Field_5', 'Field_6',\n","       'Field_7', 'Field_8', 'Field_9',\n","       ...\n","       'Field_44Field_9', 'Field_7Field_8', 'Field_7Field_9', 'Field_8Field_9',\n","       'F_startDateF_endDate', 'E_startDateE_endDate', 'C_startDateC_endDate',\n","       'G_startDateG_endDate', 'A_startDateA_endDate', 'gender'],\n","      dtype='object', length=222)\n","Bureau df shape: (73411, 151)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4172: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  method=method,\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.obj[item] = s\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"},{"output_type":"stream","text":["(53030, 132)\n","(20381, 132)\n","Preprocess - done in 17s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XspMLXaH-AY5","outputId":"bf94ac6f-61fa-465e-b697-7b145d48babb","colab":{"base_uri":"https://localhost:8080/","height":390}},"source":["with timer(\"Kfold\"):\n","    preds = kfold(train_fe,y_label,test_fe)\n","    df_test[\"label\"] = preds\n","    df_test[['id', 'label']].to_csv('submission.csv', index=False)\n","#display_importances(feature_importance_df)   "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training until validation scores don't improve for 800 rounds.\n","[200]\ttraining's auc: 0.770316\ttraining's gini: 0.540632\tvalid_1's auc: 0.733046\tvalid_1's gini: 0.466089\n","[400]\ttraining's auc: 0.799762\ttraining's gini: 0.599525\tvalid_1's auc: 0.740892\tvalid_1's gini: 0.481781\n","[600]\ttraining's auc: 0.823568\ttraining's gini: 0.647135\tvalid_1's auc: 0.74515\tvalid_1's gini: 0.4903\n","[800]\ttraining's auc: 0.842453\ttraining's gini: 0.684907\tvalid_1's auc: 0.747033\tvalid_1's gini: 0.494061\n","[1000]\ttraining's auc: 0.857797\ttraining's gini: 0.715592\tvalid_1's auc: 0.747736\tvalid_1's gini: 0.495473\n","[1200]\ttraining's auc: 0.870806\ttraining's gini: 0.741612\tvalid_1's auc: 0.748326\tvalid_1's gini: 0.496646\n","[1400]\ttraining's auc: 0.881676\ttraining's gini: 0.76335\tvalid_1's auc: 0.748658\tvalid_1's gini: 0.497318\n","[1600]\ttraining's auc: 0.891555\ttraining's gini: 0.783108\tvalid_1's auc: 0.749086\tvalid_1's gini: 0.49817\n","[1800]\ttraining's auc: 0.900332\ttraining's gini: 0.800665\tvalid_1's auc: 0.749352\tvalid_1's gini: 0.498706\n","[2000]\ttraining's auc: 0.908194\ttraining's gini: 0.816388\tvalid_1's auc: 0.749453\tvalid_1's gini: 0.4989\n","[2200]\ttraining's auc: 0.915126\ttraining's gini: 0.830256\tvalid_1's auc: 0.749108\tvalid_1's gini: 0.498212\n","[2400]\ttraining's auc: 0.921557\ttraining's gini: 0.843111\tvalid_1's auc: 0.749016\tvalid_1's gini: 0.498029\n","[2600]\ttraining's auc: 0.927163\ttraining's gini: 0.854328\tvalid_1's auc: 0.749158\tvalid_1's gini: 0.498314\n","Early stopping, best iteration is:\n","[1933]\ttraining's auc: 0.905672\ttraining's gini: 0.811345\tvalid_1's auc: 0.749514\tvalid_1's gini: 0.499022\n","Fold 0: 0.811345111935735/0.499022367020228\n","Training until validation scores don't improve for 800 rounds.\n","[200]\ttraining's auc: 0.768389\ttraining's gini: 0.536776\tvalid_1's auc: 0.72963\tvalid_1's gini: 0.459278\n","[400]\ttraining's auc: 0.798795\ttraining's gini: 0.597591\tvalid_1's auc: 0.73914\tvalid_1's gini: 0.478278\n","[600]\ttraining's auc: 0.82209\ttraining's gini: 0.644177\tvalid_1's auc: 0.74375\tvalid_1's gini: 0.487504\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7MOo-yN7QN8J"},"source":["0.5082305588525496"]}]}