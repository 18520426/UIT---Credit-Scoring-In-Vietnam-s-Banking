{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"kalapa2020.ipynb","provenance":[],"authorship_tag":"ABX9TyOcBDOEWsKc1QTyAW6ePRpd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wb67d3-0Rz9E","executionInfo":{"status":"ok","timestamp":1600385267719,"user_tz":-420,"elapsed":28765,"user":{"displayName":"Trần Quốc Khánh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVFfhxvf9yjuqauX7S1hOIYkYyKbpLDYlcZz-=s64","userId":"04381164842406200205"}},"outputId":"15156b09-4abc-4d90-c3fe-4cfe34d0c000","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l14CfxrtSEbk","executionInfo":{"status":"ok","timestamp":1600385286560,"user_tz":-420,"elapsed":1122,"user":{"displayName":"Trần Quốc Khánh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVFfhxvf9yjuqauX7S1hOIYkYyKbpLDYlcZz-=s64","userId":"04381164842406200205"}},"outputId":"6fa0fc54-89ec-4e4a-e12f-ecc8391b4634","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/kalapa"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/kalapa\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Cu_Iw1vJSFRX","executionInfo":{"status":"ok","timestamp":1600385302367,"user_tz":-420,"elapsed":15131,"user":{"displayName":"Trần Quốc Khánh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVFfhxvf9yjuqauX7S1hOIYkYyKbpLDYlcZz-=s64","userId":"04381164842406200205"}},"outputId":"be90d8e7-d4b7-4b21-ce04-2a5fc76c2554","colab":{"base_uri":"https://localhost:8080/","height":445}},"source":["!pip install feature_engine\n","!pip install unidecode"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting feature_engine\n","  Downloading https://files.pythonhosted.org/packages/d3/36/651f586a52495f6eba6613eafb6e9238a259fd78ece78b03486042a0ff71/feature_engine-0.6.0-py2.py3-none-any.whl\n","Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (1.18.5)\n","Collecting statsmodels>=0.11.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/93/1b6882f92d94e491a3e3be101fc83934551eada261281980f3957246432f/statsmodels-0.12.0-cp36-cp36m-manylinux1_x86_64.whl (9.5MB)\n","\u001b[K     |████████████████████████████████| 9.5MB 11.1MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (1.4.1)\n","Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (1.0.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.2->feature_engine) (0.16.0)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.1)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.3->feature_engine) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5->statsmodels>=0.11.1->feature_engine) (1.15.0)\n","Installing collected packages: statsmodels, feature-engine\n","  Found existing installation: statsmodels 0.10.2\n","    Uninstalling statsmodels-0.10.2:\n","      Successfully uninstalled statsmodels-0.10.2\n","Successfully installed feature-engine-0.6.0 statsmodels-0.12.0\n","Collecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\u001b[K     |████████████████████████████████| 245kB 6.3MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3V7dB754SHQc"},"source":["from itertools import combinations\n","\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from itertools import combinations\n","\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import math\n","import re\n","import warnings\n","\n","import lightgbm as lgb\n","from unidecode import unidecode\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","from feature_engine import categorical_encoders as ce\n","\n","from itertools import combinations\n","from datetime import datetime\n","from contextlib import contextmanager"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2qczmPdqSLjh"},"source":["lgbm_param = {'boosting_type': 'gbdt', \n","              'colsample_bytree': 0.6602479798930369, \n","              'is_unbalance': False, \n","              'learning_rate': 0.01,\n","              'max_depth': 15, \n","              'metric': 'auc', \n","              'min_child_samples': 25, \n","              'num_leaves': 80,\n","              'objective': 'binary', \n","              'reg_alpha': 0.4693391197064131, \n","              'reg_lambda': 0.16175478669541327, \n","              'subsample_for_bin': 60000}\n","\n","NUM_BOOST_ROUND= 10000\n","\n","DROP = [\"gioiTinh\",\"info_social_sex\", 'currentLocationCity', 'currentLocationName', 'homeTownCity', 'homeTownName'] + [f\"Field_{c}\" for c in [11, 14, 15, 16, 17, 18, 24,25, 26, 30, 31, 32, 33, 34,35, 37,40,45, 46, 48,49, 52, 56, 57, 68]]\n","DATE = [\"Field_{}\".format(i) for i in [5, 6, 7, 8, 9, 11, 15, 25, 32, 33, 34, 35, 40]]\n","DATETIME = [\"Field_{}\".format(i) for i in [1, 2, 43, 44]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jiM4F3KQSONK"},"source":["\n","@contextmanager\n","def timer(title):\n","    t0 = time.time()\n","    yield\n","    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n","\n","def Gini(y_true, y_pred):\n","    # check and get number of samples\n","    assert y_true.shape == y_pred.shape\n","    n_samples = y_true.shape[0]\n","\n","    # sort rows on prediction column\n","    # (from largest to smallest)\n","    arr = np.array([y_true, y_pred]).transpose()\n","    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n","    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n","\n","    # get Lorenz curves\n","    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n","    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n","    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n","\n","    # get Gini coefficients (area between curves)\n","    G_true = np.sum(L_ones - L_true)\n","    G_pred = np.sum(L_ones - L_pred)\n","\n","    # normalize to true Gini coefficient\n","    return G_pred * 1. / G_true\n","\n","def lgb_gini(y_pred, dataset_true):\n","    y_true = dataset_true.get_label()\n","    return 'gini', Gini(y_true, y_pred), True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"udrX9UiSSQvz"},"source":["def subtract_date(date1,date2, df):\n","    df[date1] = pd.to_datetime(df[date1], infer_datetime_format=True)\n","    df[date2] = pd.to_datetime(df[date2], infer_datetime_format=True)\n","    df[date1+date2] = (df[date2] - df[date1]).dt.days\n","    \n","def process_ngaySinh(s):\n","    if s != s:\n","        return np.nan\n","    try:\n","        s = int(s)\n","    except ValueError:\n","        s = s.split(\" \")[0]\n","        \n","    return datetime.strptime(str(s)[:6], \"%Y%m\")\n","\n","def datetime_normalize(s):\n","    if s != s:\n","        return np.nan\n","    \n","    s = s.split(\".\")[0]\n","    if s[-1] == \"Z\":\n","        s = s[:-1]\n","        \n","    date, time = s.split(\"T\")\n","    datetime_obj = datetime.strptime(s, \"%Y-%m-%dT%H:%M:%S\")\n","    return datetime_obj\n","\n","def date_normalize(s):\n","    if s != s:\n","        return np.nan\n","    \n","    try:\n","        datetime_obj = datetime.strptime(s, \"%m/%d/%Y\")\n","    except:\n","        datetime_obj = datetime.strptime(s, \"%Y-%m-%d\")\n","        \n","    return datetime_obj\n","  \n","def process_datetime_cols(df):\n","    cat_cols = []\n","    for col in DATETIME:\n","        df[col] = df[col].apply(datetime_normalize)\n","        \n","    for col in DATE:\n","        if col == \"Field_34\":\n","            continue\n","        df[col] = df[col].apply(date_normalize)\n","\n","    df[\"Field_34\"] = df[\"Field_34\"].apply(process_ngaySinh)\n","    df[\"ngaySinh\"] = df[\"ngaySinh\"].apply(process_ngaySinh)\n","    \n","    cat_cols += DATE + DATETIME\n","    for col in DATE + DATETIME:\n","        df[col] = df[col].dt.strftime('%d-%m-%Y')\n","    \n","    subtract_date('Field_5','Field_6',df)\n","    subtrac_List = ['Field_1', 'Field_2', 'Field_43', 'Field_44', 'Field_7','Field_8', 'Field_9']\n","    subtract_2C = list(combinations(subtrac_List, 2))\n","    for l in subtract_2C:\n","        subtract_date(l[0],l[1],df)\n","      \n","    for cat in ['F', 'E', 'C', 'G', 'A']:\n","        subtract_date(f'{cat}_startDate', f'{cat}_endDate', df)\n","    print(df.shape) \n","    return df\n","  \n","def str_normalize(s):\n","    s = str(s).strip().lower()\n","    s = re.sub(' +', \" \", s)\n","    return s\n","\n","def process_location(df):\n","    for col in [\"currentLocationLocationId\", \"homeTownLocationId\", \"currentLocationLatitude\", \"currentLocationLongitude\", \n","                   \"homeTownLatitude\", \"homeTownLongitude\"]:\n","        df[col].replace(0, np.nan, inplace=True)\n","\n","#     df[\"currentLocationLocationId\"] = df[\"currentLocationLocationId\"].apply(str_normalize).astype(\"category\")\n","#     df[\"homeTownLocationId\"] = df[\"homeTownLocationId\"].apply(str_normalize).astype(\"category\")\n","\n","    return df\n","\n","    \n","def combine_gender(s):\n","    x, y = s\n","    return x if x != None else y if y != None else None\n","\n","def process_gender(df):\n","    df[\"gender\"] = df[[\"gioiTinh\", \"info_social_sex\"]].apply(combine_gender, axis=1).astype(\"category\")\n","    return df\n","\n","def process_ordinal(df):        \n","    df[\"subscriberCount\"].replace(0, np.nan, inplace=True)\n","    df[\"friendCount\"].replace(0, np.nan, inplace=True)\n","    \n","    df[\"Field_13\"] = df[\"Field_13\"].apply(lambda x: 1 if x == x else 0)\n","    df[\"Field_38\"] = df[\"Field_38\"].map({0: 0.0, 1: 1.0, \"DN\": np.nan, \"TN\": np.nan, \"GD\": np.nan})\n","    df[\"Field_62\"] = df[\"Field_62\"].map({\"I\": 1, \"II\": 2, \"III\": 3, \"IV\": 4, \"V\": 5, \"Ngoài quốc doanh Quận 7\": np.nan})\n","    df[\"Field_47\"] = df[\"Field_47\"].map({\"Zezo\": 0, \"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4})\n","    \n","    df[\"Field_27\"] = df[\"Field_27\"].replace({0.0: np.nan})\n","    df[\"Field_28\"] = df[\"Field_28\"].replace({0.0: np.nan})\n","        \n","    for col in df.columns:\n","        if df[col].dtype.name == \"object\":\n","            df[col] = df[col].apply(str_normalize).astype(\"category\")\n","            \n","    return df\n","\n","def transform(df):\n","    df = process_datetime_cols(df)\n","    df = process_gender(df)\n","    df = process_location(df)\n","    df = process_ordinal(df)\n","    df[\"null_sum\"] = df.isnull().sum(axis=1)\n","    return df.drop(DROP, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dYKwUG9dSTCw"},"source":["def kfold(train_fe,y_label,test_fe):\n","    seeds = np.random.randint(0, 10000, 1)\n","    preds = 0    \n","    feature_important = None\n","    avg_train_gini = 0\n","    avg_val_gini = 0\n","\n","    for s in seeds:\n","        skf = StratifiedKFold(n_splits=5, random_state = 6484, shuffle=True)        \n","        lgbm_param['random_state'] = 6484    \n","        seed_train_gini = 0\n","        seed_val_gini = 0\n","        for i, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(y_label)), y_label)):                \n","            X_train, X_val = train_fe.iloc[train_idx].drop([\"id\"], 1), train_fe.iloc[val_idx].drop([\"id\"], 1)                \n","            y_train, y_val = y_label[train_idx], y_label[val_idx]\n","\n","            lgb_train = lgb.Dataset(X_train, y_train)\n","            lgb_eval  = lgb.Dataset(X_val, y_val)\n","\n","            evals_result = {}\n","            model = lgb.train(lgbm_param,\n","                        lgb_train,\n","                        num_boost_round=NUM_BOOST_ROUND,  \n","                        early_stopping_rounds=400,\n","                        feval=lgb_gini,\n","                        verbose_eval= 200,\n","                        evals_result=evals_result,\n","                        valid_sets=[lgb_train, lgb_eval])\n","\n","            seed_train_gini += model.best_score[\"training\"][\"gini\"] / skf.n_splits\n","            seed_val_gini += model.best_score[\"valid_1\"][\"gini\"] / skf.n_splits\n","\n","            avg_train_gini += model.best_score[\"training\"][\"gini\"] / (len(seeds) * skf.n_splits)\n","            avg_val_gini += model.best_score[\"valid_1\"][\"gini\"] / (len(seeds) * skf.n_splits)\n","\n","            if feature_important is None:\n","                feature_important = model.feature_importance() / (len(seeds) * skf.n_splits)\n","            else:\n","                feature_important += model.feature_importance() / (len(seeds) * skf.n_splits)        \n","\n","            pred = model.predict(test_fe.drop([\"id\"], 1))\n","            preds += pred / (skf.n_splits * len(seeds))\n","\n","            print(\"Fold {}: {}/{}\".format(i, model.best_score[\"training\"][\"gini\"], model.best_score[\"valid_1\"][\"gini\"]))\n","        print(\"Seed {}: {}/{}\".format(s, seed_train_gini, seed_val_gini))\n","\n","    print(\"-\" * 50)\n","    print(\"Avg train gini: {}\".format(avg_train_gini))\n","    print(\"Avg valid gini: {}\".format(avg_val_gini))\n","    print(\"=\" * 50)\n","    return preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T_TwkwvsSWaF","executionInfo":{"status":"ok","timestamp":1600385876363,"user_tz":-420,"elapsed":22299,"user":{"displayName":"Trần Quốc Khánh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVFfhxvf9yjuqauX7S1hOIYkYyKbpLDYlcZz-=s64","userId":"04381164842406200205"}},"outputId":"f79775cf-5b3b-41a0-d000-05f9dc02d979","colab":{"base_uri":"https://localhost:8080/","height":921}},"source":["df_train = pd.read_csv('/content/drive/My Drive/kalapa/train_old.csv')\n","df_test = pd.read_csv('/content/drive/My Drive/kalapa/dataset/test.csv')\n","df_a = pd.read_csv('/content/drive/My Drive/kalapa/dataset/train.csv')\n","df_all = df_train.drop(['label'], 1).append(df_test)\n","    \n","with timer(\"Preprocess\"):\n","    df_all_fe = transform(df_all.copy())\n","    print(\"Bureau df shape:\", df_all_fe.shape)\n","    df_all_fe['Age'] = df_all_fe.ngaySinh.apply(lambda x: 2020 - x.year)\n","    df_all_fe = df_all_fe.drop('ngaySinh', axis = 1)\n","    cols_select = [x for x in df_all_fe.columns if x not in DATE + DATETIME  + [f'{cat}_endDate' for cat in ['F', 'E', 'C', 'G', 'A']] + [f'{cat}_startDate' for cat in ['F', 'E', 'C', 'G', 'A']]]\n","    df_fe = df_all_fe[cols_select]\n","    df_fe.replace([np.inf, -np.inf], -99999, inplace=True)\n","\n","    y_label = df_train[\"label\"]\n","    train_fe = df_fe[df_fe[\"id\"] < df_train.shape[0]]\n","    test_fe = df_fe[df_fe[\"id\"] >= df_train.shape[0]]\n","\n","    # Label-Encoding\n","    lbl = LabelEncoder()\n","    for col in df_fe.columns:\n","      if df_fe[col].dtype.name == \"category\":\n","        train_fe[col] = train_fe[col].astype(str)\n","        test_fe[col] = test_fe[col].astype(str)\n","        encoder = ce.CountFrequencyCategoricalEncoder(encoding_method='frequency')\n","        train_fe[col] = train_fe[col].fillna('None')\n","        test_fe[col] = test_fe[col].fillna('None')\n","\n","        # Only take the common values in Train/Test set\n","        common_vals = list(set(train_fe[col]).intersection(set(test_fe[col])))\n","\n","        # Take if vals appeared both 5 times\n","        common_vals = set(train_fe[col].value_counts()[train_fe[col].value_counts() > 4].index).intersection(test_fe[col].value_counts()[test_fe[col].value_counts()>4].index)\n","\n","        # Replace not-common values with \"Missing\" or np.nan\n","        train_fe.loc[~train_fe[col].isin(common_vals), col] = 'Missing'\n","        test_fe.loc[~test_fe[col].isin(common_vals), col] = 'Missing'\n","\n","        # Implement LE\n","        lbl.fit(train_fe[col].tolist() + test_fe[col].tolist())\n","        train_fe[col] = lbl.transform(train_fe[col])\n","        test_fe[col] = lbl.transform(test_fe[col])\n","\n","    print(train_fe.shape)\n","    print(test_fe.shape)\n","    #train_fe.to_csv(\"trainoutput.csv\")\n","    #test_fe.to_csv(\"testoutput.csv\")\n","#with timer(\"Kfold\"):\n","#    preds = kfold(train_fe,y_label,test_fe)\n","#    df_test[\"label\"] = preds\n","#    df_test[['id', 'label']].to_csv('submission.csv', index=False)\n","#display_importances(feature_importance_df)   "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (36,44) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n","/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (34,42) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n","/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (35,43) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n"],"name":"stderr"},{"output_type":"stream","text":["(73411, 232)\n","Bureau df shape: (73411, 203)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4172: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  method=method,\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.obj[item] = s\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"},{"output_type":"stream","text":["(53030, 184)\n","(20381, 184)\n","Preprocess - done in 18s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h4R10HkWzelB","executionInfo":{"status":"ok","timestamp":1600389077094,"user_tz":-420,"elapsed":3192993,"user":{"displayName":"Trần Quốc Khánh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVVFfhxvf9yjuqauX7S1hOIYkYyKbpLDYlcZz-=s64","userId":"04381164842406200205"}},"outputId":"947f62b6-a483-46f6-eb63-c438a72f146f","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def calculate_woe_iv(dataset, feature, target):\n","    lst = []\n","    for i in range(dataset[feature].nunique()):\n","        val = list(dataset[feature].unique())[i]\n","        lst.append({\n","            'Value': val,\n","            'All': dataset[dataset[feature] == val].count()[feature],\n","            'Good': dataset[(dataset[feature] == val) & (dataset[target] == 0)].count()[feature],\n","            'Bad': dataset[(dataset[feature] == val) & (dataset[target] == 1)].count()[feature]\n","        })\n","    dset = pd.DataFrame(lst)\n","    dset['Distr_Good'] = dset['Good'] / dset['Good'].sum()\n","    dset['Distr_Bad'] = dset['Bad'] / dset['Bad'].sum()\n","    dset['WoE'] = np.log(dset['Distr_Good'] / dset['Distr_Bad'])\n","    dset = dset.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n","    dset['IV'] = (dset['Distr_Good'] - dset['Distr_Bad']) * dset['WoE']\n","    iv = dset['IV'].sum()\n","    dset = dset.sort_values(by='WoE')\n","    return dset, iv\n","\n","USELESS_PREDICTOR = []\n","WEAK_PREDICTOR = []\n","MEDIUM_PREDICTOR = []\n","STRONG_PREDICTOR = []\n","GOOD_PREDICTOR = []\n","IGNORE_FEATURE = USELESS_PREDICTOR + WEAK_PREDICTOR\n","for col in df_a.columns:\n","    if col == 'label' or col == 'id': continue\n","    elif col in IGNORE_FEATURE: continue\n","    else:\n","        print('WoE and IV for column: {}'.format(col))\n","        final, iv = calculate_woe_iv(df_a, col, 'label')\n","        iv = round(iv,2)\n","        print('IV score: ' + str(iv))\n","        print('\\n')\n","        if (iv < 0.05) and col not in USELESS_PREDICTOR:\n","            USELESS_PREDICTOR.append(col)\n","        elif iv >= 0.05 and iv < 0.1 and col not in WEAK_PREDICTOR:\n","            WEAK_PREDICTOR.append(col)\n","        elif iv >= 0.1 and iv < 0.3 and col not in MEDIUM_PREDICTOR:\n","            MEDIUM_PREDICTOR.append(col)\n","        elif iv >= 0.3 and iv < 0.5 and col not in STRONG_PREDICTOR:\n","            STRONG_PREDICTOR.append(col)\n","        elif iv >= 0.5 and col not in GOOD_PREDICTOR:\n","            GOOD_PREDICTOR.append(col)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WoE and IV for column: Field_1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log\n","  result = getattr(ufunc, method)(*inputs, **kwargs)\n"],"name":"stderr"},{"output_type":"stream","text":["IV score: 0.08\n","\n","\n","WoE and IV for column: Field_2\n","IV score: 0.17\n","\n","\n","WoE and IV for column: Field_3\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_4\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_5\n","IV score: 0.23\n","\n","\n","WoE and IV for column: Field_6\n","IV score: 0.23\n","\n","\n","WoE and IV for column: Field_7\n","IV score: 0.16\n","\n","\n","WoE and IV for column: Field_8\n","IV score: 0.18\n","\n","\n","WoE and IV for column: Field_9\n","IV score: 0.23\n","\n","\n","WoE and IV for column: Field_10\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_11\n","IV score: 0.15\n","\n","\n","WoE and IV for column: Field_12\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_13\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_14\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_15\n","IV score: 0.25\n","\n","\n","WoE and IV for column: Field_16\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_17\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_18\n","IV score: 0.1\n","\n","\n","WoE and IV for column: Field_19\n","IV score: 0.04\n","\n","\n","WoE and IV for column: Field_20\n","IV score: 0.2\n","\n","\n","WoE and IV for column: Field_21\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_22\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_23\n","IV score: 0.08\n","\n","\n","WoE and IV for column: Field_24\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_25\n","IV score: 0.22\n","\n","\n","WoE and IV for column: Field_26\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_27\n","IV score: 0.02\n","\n","\n","WoE and IV for column: Field_28\n","IV score: 0.02\n","\n","\n","WoE and IV for column: Field_29\n","IV score: 0.01\n","\n","\n","WoE and IV for column: Field_30\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_31\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_32\n","IV score: 0.21\n","\n","\n","WoE and IV for column: Field_33\n","IV score: 0.18\n","\n","\n","WoE and IV for column: Field_34\n","IV score: 0.23\n","\n","\n","WoE and IV for column: Field_35\n","IV score: 0.13\n","\n","\n","WoE and IV for column: ngaySinh\n","IV score: 0.45\n","\n","\n","WoE and IV for column: namSinh\n","IV score: 0.01\n","\n","\n","WoE and IV for column: gioiTinh\n","IV score: 0.0\n","\n","\n","WoE and IV for column: diaChi\n","IV score: 0.11\n","\n","\n","WoE and IV for column: Field_36\n","IV score: 0.06\n","\n","\n","WoE and IV for column: Field_37\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_38\n","IV score: 0.01\n","\n","\n","WoE and IV for column: Field_39\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_40\n","IV score: 0.13\n","\n","\n","WoE and IV for column: Field_41\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_42\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_43\n","IV score: 0.2\n","\n","\n","WoE and IV for column: Field_44\n","IV score: 0.3\n","\n","\n","WoE and IV for column: Field_45\n","IV score: 0.34\n","\n","\n","WoE and IV for column: Field_46\n","IV score: 0.31\n","\n","\n","WoE and IV for column: Field_47\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_48\n","IV score: 0.32\n","\n","\n","WoE and IV for column: Field_49\n","IV score: 0.33\n","\n","\n","WoE and IV for column: Field_50\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_51\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_52\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_53\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_54\n","IV score: 0.01\n","\n","\n","WoE and IV for column: Field_55\n","IV score: 0.1\n","\n","\n","WoE and IV for column: Field_56\n","IV score: 0.14\n","\n","\n","WoE and IV for column: Field_57\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_58\n","IV score: 0.01\n","\n","\n","WoE and IV for column: Field_59\n","IV score: 0.09\n","\n","\n","WoE and IV for column: Field_60\n","IV score: 0.09\n","\n","\n","WoE and IV for column: Field_61\n","IV score: 0.09\n","\n","\n","WoE and IV for column: Field_62\n","IV score: 0.01\n","\n","\n","WoE and IV for column: Field_63\n","IV score: 0.01\n","\n","\n","WoE and IV for column: Field_64\n","IV score: 0.01\n","\n","\n","WoE and IV for column: Field_65\n","IV score: 0.01\n","\n","\n","WoE and IV for column: Field_66\n","IV score: 0.01\n","\n","\n","WoE and IV for column: Field_67\n","IV score: 0.31\n","\n","\n","WoE and IV for column: Field_68\n","IV score: 0.34\n","\n","\n","WoE and IV for column: maCv\n","IV score: 0.22\n","\n","\n","WoE and IV for column: Field_69\n","IV score: 0.03\n","\n","\n","WoE and IV for column: Field_70\n","IV score: 0.05\n","\n","\n","WoE and IV for column: Field_71\n","IV score: 0.07\n","\n","\n","WoE and IV for column: Field_72\n","IV score: 0.06\n","\n","\n","WoE and IV for column: Field_73\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_74\n","IV score: 0.12\n","\n","\n","WoE and IV for column: Field_75\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_76\n","IV score: 0.0\n","\n","\n","WoE and IV for column: Field_77\n","IV score: 0.0\n","\n","\n","WoE and IV for column: friendCount\n","IV score: 0.18\n","\n","\n","WoE and IV for column: info_social_sex\n","IV score: 0.0\n","\n","\n","WoE and IV for column: subscriberCount\n","IV score: 0.08\n","\n","\n","WoE and IV for column: currentLocationLocationId\n","IV score: 0.09\n","\n","\n","WoE and IV for column: currentLocationLatitude\n","IV score: 0.09\n","\n","\n","WoE and IV for column: currentLocationLongitude\n","IV score: 0.09\n","\n","\n","WoE and IV for column: homeTownLocationId\n","IV score: 0.11\n","\n","\n","WoE and IV for column: homeTownLatitude\n","IV score: 0.1\n","\n","\n","WoE and IV for column: homeTownLongitude\n","IV score: 0.09\n","\n","\n","WoE and IV for column: data.basic_info.locale\n","IV score: 0.0\n","\n","\n","WoE and IV for column: currentLocationCity\n","IV score: 0.14\n","\n","\n","WoE and IV for column: currentLocationCountry\n","IV score: 0.01\n","\n","\n","WoE and IV for column: currentLocationName\n","IV score: 0.17\n","\n","\n","WoE and IV for column: currentLocationState\n","IV score: 0.06\n","\n","\n","WoE and IV for column: homeTownCity\n","IV score: 0.2\n","\n","\n","WoE and IV for column: homeTownCountry\n","IV score: 0.01\n","\n","\n","WoE and IV for column: homeTownName\n","IV score: 0.21\n","\n","\n","WoE and IV for column: homeTownState\n","IV score: 0.06\n","\n","\n","WoE and IV for column: topFriends\n","IV score: 0.01\n","\n","\n","WoE and IV for column: numOrg\n","IV score: 0.03\n","\n","\n","WoE and IV for column: F_numOrg\n","IV score: 0.02\n","\n","\n","WoE and IV for column: F_numQuery\n","IV score: 0.0\n","\n","\n","WoE and IV for column: F_startDate\n","IV score: 0.08\n","\n","\n","WoE and IV for column: F_endDate\n","IV score: 0.08\n","\n","\n","WoE and IV for column: E_numOrg\n","IV score: 0.01\n","\n","\n","WoE and IV for column: E_numQuery\n","IV score: 0.0\n","\n","\n","WoE and IV for column: E_startDate\n","IV score: 0.08\n","\n","\n","WoE and IV for column: E_endDate\n","IV score: 0.08\n","\n","\n","WoE and IV for column: C_numOrg\n","IV score: 0.0\n","\n","\n","WoE and IV for column: C_numQuery\n","IV score: 0.01\n","\n","\n","WoE and IV for column: C_startDate\n","IV score: 0.07\n","\n","\n","WoE and IV for column: C_endDate\n","IV score: 0.08\n","\n","\n","WoE and IV for column: G_numOrg\n","IV score: 0.03\n","\n","\n","WoE and IV for column: G_numQuery\n","IV score: 0.04\n","\n","\n","WoE and IV for column: G_startDate\n","IV score: 0.08\n","\n","\n","WoE and IV for column: G_endDate\n","IV score: 0.08\n","\n","\n","WoE and IV for column: A_numOrg\n","IV score: 0.03\n","\n","\n","WoE and IV for column: A_numQuery\n","IV score: 0.02\n","\n","\n","WoE and IV for column: A_startDate\n","IV score: 0.08\n","\n","\n","WoE and IV for column: A_endDate\n","IV score: 0.09\n","\n","\n","WoE and IV for column: summary_6m\n","IV score: 0.02\n","\n","\n","WoE and IV for column: summary_3m\n","IV score: 0.02\n","\n","\n","WoE and IV for column: summary_1m\n","IV score: 0.05\n","\n","\n","WoE and IV for column: summary_1w\n","IV score: 0.04\n","\n","\n","WoE and IV for column: partner0_A\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner0_B\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner0_C\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner0_D\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner0_E\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner0_F\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner0_G\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner0_H\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner0_K\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner0_L\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner1_A\n","IV score: 0.01\n","\n","\n","WoE and IV for column: partner1_B\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner1_C\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner1_D\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner1_E\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner1_F\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner1_G\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner1_H\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner1_K\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner1_L\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner2_A\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner2_B\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner2_C\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner2_D\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner2_E\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner2_F\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner2_G\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner2_H\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner2_K\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner2_L\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner3_A\n","IV score: 0.01\n","\n","\n","WoE and IV for column: partner3_B\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner3_C\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner3_D\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner3_E\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner3_F\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner3_G\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner3_H\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner3_K\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner3_L\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner4_A\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner4_B\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner4_C\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner4_D\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner4_E\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner4_F\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner4_G\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner4_H\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner4_K\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner4_L\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner5_A\n","IV score: 0.01\n","\n","\n","WoE and IV for column: partner5_B\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner5_C\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner5_D\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner5_E\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner5_F\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner5_G\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner5_H\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner5_K\n","IV score: 0.0\n","\n","\n","WoE and IV for column: partner5_L\n","IV score: 0.0\n","\n","\n","WoE and IV for column: brief\n","IV score: 0.32\n","\n","\n","WoE and IV for column: num_of_phone\n","IV score: 0.01\n","\n","\n","WoE and IV for column: Field_78\n","IV score: 0.08\n","\n","\n","WoE and IV for column: Field_79\n","IV score: 0.24\n","\n","\n","WoE and IV for column: Field_80\n","IV score: 0.22\n","\n","\n","WoE and IV for column: Field_81\n","IV score: 0.08\n","\n","\n","WoE and IV for column: Field_82\n","IV score: 0.26\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HGayBDvSzjkI"},"source":["B = pd.DataFrame(STRONG_PREDICTOR)\n","B.to_csv(\"STRONG.csv\", index = True)\n","\n","C = pd.DataFrame(MEDIUM_PREDICTOR)\n","C.to_csv(\"MEDIUM.csv\", index = True)\n","\n","D = pd.DataFrame(WEAK_PREDICTOR)\n","D.to_csv(\"WEAK.csv\", index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IU0X6oXyqT_t"},"source":["B = pd.DataFrame(USELESS_PREDICTOR)\n","B.to_csv(\"UESLESS.csv\", index = True)"],"execution_count":null,"outputs":[]}]}