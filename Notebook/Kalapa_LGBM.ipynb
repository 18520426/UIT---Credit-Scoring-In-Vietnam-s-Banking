{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Kalapa_LGBM.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"gV9QDy-bDHzm"},"source":["import os, sys, re\n","import numpy as np\n","import pandas as pd\n","import matplotlib\n","import pickle\n","import tarfile\n","from datetime import datetime\n","from subprocess import call, Popen\n","from scipy import interp\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import auc\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import plot_roc_curve\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1aeB8I9HNFOG","outputId":"fec27ca7-f833-4093-8d73-ce788098e677","colab":{"base_uri":"https://localhost:8080/","height":408}},"source":["!pip install feature_engine\n","!pip install unidecode\n","!pip install category_encoders"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: feature_engine in /usr/local/lib/python3.6/dist-packages (0.6.0)\n","Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (0.22.2.post1)\n","Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (0.12.0)\n","Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (1.0.5)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (1.4.1)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (1.18.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.2->feature_engine) (0.16.0)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.3->feature_engine) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5->statsmodels>=0.11.1->feature_engine) (1.15.0)\n","Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n","Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.2.2)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.12.0)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.5)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n","Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.0.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.16.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lJU_PZCVDqBv"},"source":["matplotlib.use(\"pdf\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JBV_RMN7DshI","outputId":"51a72646-e176-4c2c-e63c-77425e92f8d9","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wnCJmCMVD4OU","outputId":"576b7f63-e538-4504-c668-bfcb3c65d484","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/kalapa"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/kalapa\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_Wuf8IHoEBGt","outputId":"a24edc81-c4bb-466b-ef71-44bc0d07064a","colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["train_df = pd.read_csv(\"/content/drive/My Drive/kalapa/dataset/train.csv\")\n","test_df = pd.read_csv(\"/content/drive/My Drive/kalapa/dataset/test.csv\")\n","df_all = train_df.drop(['label'], 1).append(test_df)\n","\n","print(\"Train: \", train_df.shape, \" | Test: \", test_df.shape, \" |  All: \", df_all.shape)\n","\n","print(\"-\"*70)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (35,43) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n","/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (34,42) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n"],"name":"stderr"},{"output_type":"stream","text":["Train:  (53030, 195)  | Test:  (20381, 194)  |  All:  (73411, 194)\n","----------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sOw1FlkNGMV6"},"source":["##Updated start here\n","DROP = ([\"gioiTinh\",\"info_social_sex\", 'currentLocationLocationId', 'currentLocationLatitude', 'currentLocationLongitude', 'homeTownLocationId', 'homeTownLatitude', 'homeTownLongitude', 'currentLocationName', 'homeTownName', 'diaChi'] + \n","[f\"Field_{c}\" for c in [1, 3, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 76, 77]] + \n","[  'partner0_A', 'partner0_B', 'partner0_C', 'partner0_D', 'partner0_E', 'partner0_F', 'partner0_H', 'partner0_H', 'partner0_K', 'partner0_L', \n","   'partner1_B', 'partner1_C', 'partner1_D', 'partner1_E', 'partner1_F', 'partner1_G', 'partner1_H', 'partner1_K', 'partner1_L', \n","   'partner2_A', 'partner2_B', 'partner2_C', 'partner2_D', 'partner2_E', 'partner2_G', 'partner2_H', 'partner2_K', 'partner2_L', \n","   'partner3_B', 'partner3_C', 'partner3_E', 'partner3_F', 'partner3_G', 'partner3_H', 'partner3_K', 'partner3_L', \n","   'partner4_A', 'partner4_B', 'partner4_C', 'partner4_D', 'partner4_E', 'partner4_F', 'partner4_G', 'partner4_H', 'partner4_K', 'partner4_L', \n","   'partner5_B', 'partner5_C', 'partner5_D', 'partner5_E', 'partner5_F', 'partner5_G','partner5_H', 'partner5_K', 'partner5_L'])\n","\n","cat_features_count_encode = ['Field_4', 'Field_12', 'Field_18', 'Field_34', 'gioiTinh', 'diaChi', 'Field_36',\n","                             'Field_38', 'Field_45', 'Field_46', 'Field_47', 'Field_48', 'Field_49',\n","                             'Field_54', 'Field_55', 'Field_56', 'Field_61', 'Field_62', 'Field_65', 'Field_66',\n","                             'Field_68', 'maCv', 'info_social_sex', 'data.basic_info.locale',\n","                             'currentLocationCountry', 'currentLocationState', 'homeTownCountry', 'homeTownState', 'brief']\n","\n","unidecode_columns = 'diaChi currentLocationCountry currentLocationState homeTownCountry homeTownState maCv'.split()\n","DATE = [\"Field_{}\".format(i) for i in [5, 6, 7, 8, 9, 11, 15, 25, 32, 33, 35, 40]]\n","DATETIME = [\"Field_{}\".format(i) for i in [1, 2, 43, 44]]\n","##End"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oyg3frxjJhm1"},"source":["def subtract_date(date1,date2, df):\n","    df[date1] = pd.to_datetime(df[date1], infer_datetime_format=True)\n","    df[date2] = pd.to_datetime(df[date2], infer_datetime_format=True)\n","    df[date1+date2] = (df[date2] - df[date1]).dt.days\n","    \n","def process_ngaySinh(s):\n","    if s != s:\n","        return np.nan\n","    try:\n","        s = int(s)\n","    except ValueError:\n","        s = s.split(\" \")[0]\n","        \n","    return datetime.strptime(str(s)[:6], \"%Y%m\")\n","\n","def datetime_normalize(s):\n","    if s != s:\n","        return np.nan\n","        \n","    s = s.split(\".\")[0]\n","    if s[-1] == \"Z\":\n","        s = s[:-1]\n","        \n","    date, time = s.split(\"T\")\n","    datetime_obj = datetime.strptime(s, \"%Y-%m-%dT%H:%M:%S\")\n","    return datetime_obj\n","\n","def date_normalize(s):\n","    if s != s:\n","        return np.nan\n","    \n","    try:\n","        datetime_obj = datetime.strptime(s, \"%m/%d/%Y\")\n","    except:\n","        datetime_obj = datetime.strptime(s, \"%Y-%m-%d\")\n","        \n","    return datetime_obj\n","  \n","def process_datetime_cols(df):\n","    cat_cols = []\n","    for col in DATETIME:\n","        df[col] = df[col].apply(datetime_normalize)\n","        \n","    for col in DATE:\n","        if col == \"Field_34\":\n","            continue\n","        df[col] = df[col].apply(date_normalize)\n","\n","    df[\"Field_34\"] = df[\"Field_34\"].apply(process_ngaySinh)\n","    df[\"ngaySinh\"] = df[\"ngaySinh\"].apply(process_ngaySinh)\n","    \n","    cat_cols += DATE + DATETIME\n","    for col in DATE + DATETIME:\n","        #df[col].fillna(0)\n","        df[col] = df[col].dt.strftime('%m-%Y') #%d-%m-%Y\n","    \n","    subtract_date('Field_5','Field_6',df)\n","    subtrac_List = ['Field_1', 'Field_2', 'Field_43', 'Field_44', 'Field_7','Field_8', 'Field_9']\n","    subtract_2C = list(combinations(subtrac_List, 2))\n","    for l in subtract_2C:\n","        subtract_date(l[0],l[1],df)\n","      \n","    for cat in ['F', 'E', 'C', 'G', 'A']:\n","        subtract_date(f'{cat}_startDate', f'{cat}_endDate', df)\n","    for col in cat_cols:\n","        df[col] = df[col].astype(\"category\")\n","    print(df.shape) \n","    return df\n","\n","def str_normalize(s):\n","    s = str(s).strip().lower()\n","    s = re.sub(r\"\t\", \" \", s)\n","    s = re.sub(r\" \", \" \", s) # b'\\xc2\\xa0'\n","    return s\n","\n","def str_normalize1(s):\n","    s = str(s).strip().lower()\n","    s = re.sub(' +', \" \", s)\n","    return s\n","\n","def process_location(df):\n","    for col in [\"currentLocationLocationId\", \"homeTownLocationId\", \"currentLocationLatitude\", \"currentLocationLongitude\", \n","                   \"homeTownLatitude\", \"homeTownLongitude\"]:\n","        df[col].replace(0, np.nan, inplace=True)\n","\n","    df[\"currentLocationLocationId\"] = df[\"currentLocationLocationId\"].apply(str_normalize).astype(\"category\")\n","    df[\"homeTownLocationId\"] = df[\"homeTownLocationId\"].apply(str_normalize).astype(\"category\")\n","\n","    return df\n","\n","def job_category(x):\n","    if type(x) == str:\n","        if \"công nhân\" in x or \"cnv\" in x or \"cn\" in x or \"may công nghiệp\" in x or \"lao động\" in x\\\n","        or \"thợ\" in x or \"coõng nhaõn trửùc tieỏp maựy may coõng nghieọp\" in x or \"c.n\" in x or \"lđ\" in x:\n","            return \"CN\"\n","        elif \"giáo viên\" in x or \"gv\" in x or \"gíao viên\" in x:\n","            return \"GV\"\n","        elif \"nhân viên\" in x or \"kế toán\" in x or \"cán bộ\" in x or \"nv\" in x or \"cb\" in x or \"nhõn viờn\" in x:\n","            return \"NV\"\n","        elif \"tài xế\" in x or \"lái\" in x or \"tài xê\" in x:\n","            return \"TX\"\n","        elif \"quản lý\" in x or \"phó phòng\" in x or \"hiệu phó\" in x:\n","            return \"QL\"\n","        elif \"undefined\" in x:\n","            return \"missing\"\n","        elif \"giám đốc\" in x or \"hiệu trưởng\" in x:\n","            return \"GĐ\"\n","        elif \"phục vụ\" in x:\n","            return \"PV\"\n","        elif \"chuyên viên\" in x:\n","            return  \"CV\"\n","        elif \"bác sĩ\" in x or \"dược sĩ\" in x or \"y sĩ\" in x or \"y sỹ\" in x:\n","            return \"BS\"\n","        elif \"y tá\" in x:\n","            return \"YT\"\n","        elif \"hộ sinh\" in x:\n","            return \"HS\"\n","        elif \"chủ tịch\" in x:\n","            return \"CT\"\n","        elif \"bếp\" in x:\n","            return \"ĐB\"\n","        elif \"sư\" in x:\n","            return \"KS\"\n","        elif \"dưỡng\" in x:\n","            return \"ĐD\"\n","        elif \"kỹ thuật\" in x or \"kĩ thuật\" in x:\n","            return \"KTV\"\n","        elif \"diễn viên\" in x:\n","            return \"DV\"\n","        else:\n","            return \"missing\"\n","    else:\n","        return x \n","\n","def process_diaChi_maCv(df):\n","    df[\"maCv\"] = df[\"maCv\"].apply(str_normalize).apply(job_category).astype(\"category\")\n","    return df\n","\n","def combine_gender(s):\n","    x, y = s\n","    if x != x and y != y:\n","        return \"nan\"\n","    \n","    if x != x:\n","        return y.lower()\n","    \n","    return x.lower()\n","\n","def process_gender(df):\n","    df[\"gender\"] = df[[\"gioiTinh\", \"info_social_sex\"]].apply(combine_gender, axis=1).astype(\"category\")\n","    return df\n","\n","def process_ordinal(df):\n","    print(df.columns)\n","\n","    df[\"subscriberCount\"].replace(0, np.nan, inplace=True)\n","    df[\"friendCount\"].replace(0, np.nan, inplace=True)\n","\n","    df[\"Field_13\"] = df[\"Field_13\"].apply(lambda x: 1 if x == x else 0)\n","    df[\"Field_38\"] = df[\"Field_38\"].map({0: 0.0, 1: 1.0, \"DN\": np.nan, \"TN\": np.nan, \"GD\": np.nan})\n","    df[\"Field_62\"] = df[\"Field_62\"].map({\"I\": 1.0, \"II\": 2.0, \"III\": 3.0, \"IV\": 4.0, \"V\": 5.0, \"Ngoài quốc doanh Quận 7\": np.nan})\n","    df[\"Field_47\"] = df[\"Field_47\"].map({\"Zezo\": 0.0, \"One\": 1.0, \"Two\": 2.0, \"Three\": 3.0, \"Four\": 4.0})\n","    df[\"Field_66\"] = df[\"Field_66\"].map({\"B\": 0.0, \"C\": 1.0, \"D\": 2.0, \"E\": 3.0, \"F\": 4.0, \"G\": 5.0, \"H\": 6.0, \"I\": 7.0})\n","\n","    df[\"Field_27\"] = df[\"Field_27\"].replace({0.0: np.nan})\n","    df[\"Field_28\"] = df[\"Field_28\"].replace({0.0: np.nan})\n","        \n","    for col in df.columns:\n","        if df[col].dtype.name == \"object\":\n","            df[col] = df[col].apply(str_normalize).astype(\"category\")\n","            \n","    return df\n","\n","def transform(df):\n","    df[\"gioiTinh\"] = df[\"gioiTinh\"].str.lower()\n","    df[\"maCv\"] = df[\"maCv\"].str.lower()\n","    #df = process_datetime_cols(df)\n","    df = process_gender(df)\n","    df = process_location(df)\n","    df = process_diaChi_maCv(df)\n","    df = process_ordinal(df)\n","    #df[unidecode_columns] = df[unidecode_columns].applymap(lambda x: unidecode(x).lower() if x == x else x)\n","    #print(df[unidecode_columns])\n","    #df[cat_features_count_encode] = df[cat_features_count_encode].astype('category')\n","    df[\"null_sum\"] = df.isnull().sum(axis=1)\n","    DROP1 = DROP + DATE + DATETIME\n","    return df.drop(DROP1, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5eCHr7OcENpu","outputId":"7e03349c-8235-4283-95fe-f04fb7aacccd","colab":{"base_uri":"https://localhost:8080/","height":816}},"source":["from sklearn.preprocessing import LabelEncoder\n","from feature_engine import categorical_encoders as ce\n","print(\"\\n@Data Pre-Processing\")\n","\n","print(\"\\n+ Feature Engineering\")\n","\n","df_all_fe = transform(df_all)\n","\n","df_all_fe.ngaySinh.fillna(0, inplace=True)\n","\n","df_all_fe['Age'] = df_all_fe.ngaySinh.apply(lambda x: (2020 - int(x/10000)) if (x != 0) else x)\n","df_all_fe['Age'] = df_all_fe.Age.apply(lambda x: x if (x >= 18 and x <= 65) else 0)\n","df_all_fe['Field_34'] = df_all_fe.Field_34.apply(lambda x: str(x)[:6])\n","df_all_fe = df_all_fe.drop('ngaySinh', axis = 1)\n","#print(df_all_fe)\n","cols_select = [x for x in df_all_fe.columns if x not in DROP]\n","df_fe = df_all_fe[cols_select]\n","df_fe.replace([np.inf, -np.inf], -99999, inplace=True)\n","#print(df_fe)\n","\n","y_label = train_df[\"label\"]\n","train_fe = df_fe[df_fe[\"id\"] < 53030]\n","test_fe = df_fe[df_fe[\"id\"] >= 53030]\n","\n","# Label-Encoding\n","lbl = LabelEncoder()\n","for col in df_fe.columns:\n","  if df_fe[col].dtype.name == \"category\":\n","    train_fe[col] = train_fe[col].astype(str)\n","    test_fe[col] = test_fe[col].astype(str)\n","    encoder = ce.CountFrequencyCategoricalEncoder(encoding_method='frequency')\n","    train_fe[col] = train_fe[col].fillna('None')\n","    test_fe[col] = test_fe[col].fillna('None')\n","\n","    # Only take the common values in Train/Test set\n","    common_vals = list(set(train_fe[col]).intersection(set(test_fe[col])))\n","\n","    # Take if vals appeared both 5 times\n","    common_vals = set(train_fe[col].value_counts()[train_fe[col].value_counts() > 4].index).intersection(test_fe[col].value_counts()[test_fe[col].value_counts()>4].index)\n","\n","    # Replace not-common values with \"Missing\" or np.nan\n","    train_fe.loc[~train_fe[col].isin(common_vals), col] = 'Missing'\n","    test_fe.loc[~test_fe[col].isin(common_vals), col] = 'Missing'\n","\n","    # Implement LE\n","    lbl.fit(train_fe[col].tolist() + test_fe[col].tolist())\n","    train_fe[col] = lbl.transform(train_fe[col])\n","    test_fe[col] = lbl.transform(test_fe[col])\n","\n","print(\"train_df.shape = \", train_fe.shape, \" | test_df.shape = \", test_fe.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","@Data Pre-Processing\n","\n","+ Feature Engineering\n","Index(['id', 'Field_1', 'Field_2', 'Field_3', 'Field_4', 'Field_5', 'Field_6',\n","       'Field_7', 'Field_8', 'Field_9',\n","       ...\n","       'partner5_L', 'brief', 'num_of_phone', 'Field_78', 'Field_79',\n","       'Field_80', 'Field_81', 'Field_82', 'gender', 'null_sum'],\n","      dtype='object', length=196)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.obj[item] = s\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"},{"output_type":"stream","text":["train_df.shape =  (53030, 72)  | test_df.shape =  (20381, 72)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m8j6srTBxS6n"},"source":["temp_train = train_df[['label']]\n","#temp_test = test_df[['Field_2', 'Field_5', 'Field_6', 'Field_7', 'Field_8']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7fQVum3nsoTF","outputId":"72a86c7b-8cf1-4476-b0f4-a990dcbd267e","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["#Fill NaN values\n","train_fe = pd.concat([train_fe, temp_train], axis = 1)\n","train_fe.fillna(-1, inplace=True)\n","test_fe.fillna(-1, inplace=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4153: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"fTxtkcNVGfiB","outputId":"500f103a-2483-4644-ae36-0232a6a5b6db","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# WOE Binning\n","bin_num_limit = 8\n","stop_limit = 0.05\n","count_distr_limit = 0.05\n","cd1 = '/content/drive/My Drive/kalapa'\n","\n","##From here\n","woe_cols = [\n","    'Field_18', 'Field_20', 'Field_23',\n","    'Field_34', 'Field_45', 'Field_46', 'Field_48', 'Field_49', 'Field_55', 'Field_56',\n","    'Field_67', 'Field_71', 'Field_72', 'Field_73', 'Field_74', 'Field_75', 'Field_78', 'Field_79', \n","    'Field_80', 'Field_81', 'Field_82', 'summary_1w', 'summary_1m', 'summary_3m', 'summary_6m',\n","    'currentLocationCity', 'homeTownCity', 'Age', 'A_numOrg', 'numOrg',\n","    'friendCount', 'gender', 'num_of_phone', 'subscriberCount', 'null_sum', 'topFriends'\n","]\n","##To there\n","\n","commands = []\n","for col_name in woe_cols:\n","    os.makedirs(os.path.join(cd1, \"woe/%s\"%col_name), exist_ok=True)\n","    df1 = train_fe[[\"id\", \"label\", col_name]]\n","    df2 = test_fe[[\"id\", col_name]]\n","    df1.to_csv(os.path.join(cd1, \"woe/%s/train.csv\"%col_name), index=False, encoding=\"utf-8\")\n","    df2.to_csv(os.path.join(cd1, \"woe/%s/test.csv\"%col_name), index=False, encoding=\"utf-8\")\n","\n","    print(f\"Binning: {col_name}\", f\"bin_num_limit={bin_num_limit}\", f\"stop_limit={stop_limit}\", f\"count_distr_limit={count_distr_limit}\")\n","    commands.append(\n","        f\"Rscript woe.r {cd1}/woe {col_name} {bin_num_limit} {stop_limit} {count_distr_limit}\"\n","    )\n","\n","#procs = [Popen(c.strip().split()) for c in commands]\n","#for p in procs:\n","#    p.wait()\n","\n","\n","#START FROM HERE\n","train_woe_df = {}\n","test_woe_df = {}\n","for col_name in woe_cols:\n","    df1 = pd.read_csv(os.path.join(cd1, 'woe/%s/train_woe.csv'%col_name))\n","    df2 = pd.read_csv(os.path.join(cd1, 'woe/%s/test_woe.csv'%col_name))\n","    for c in df1.columns:\n","        train_woe_df[c] = df1[c]\n","    for c in df2.columns:\n","        test_woe_df[c] = df2[c]\n","\n","train_fe_df = pd.DataFrame.from_dict(train_woe_df)\n","test_fe_df = pd.DataFrame.from_dict(test_woe_df)\n","\n","print(\" \"*4, \"After dropping: \", train_fe_df.shape, test_fe_df.shape)\n","print(\"-\"*40)\n","\n","print(\"Done!\")\n","print(\"-\"*60)\n","\n","train_fe_df.to_csv(os.path.join(cd1, \"train_fe.csv\"), index=False, encoding=\"utf-8\")\n","test_fe_df.to_csv(os.path.join(cd1, \"test_fe.csv\"), index=False, encoding=\"utf-8\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Binning: Field_18 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_20 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_23 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_34 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_45 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_46 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_48 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_49 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_55 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_56 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_67 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_71 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_72 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_73 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_74 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_75 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_78 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_79 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_80 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_81 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Field_82 bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: summary_1w bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: summary_1m bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: summary_3m bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: summary_6m bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: currentLocationCity bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: homeTownCity bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: Age bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: A_numOrg bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: numOrg bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: friendCount bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: gender bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: num_of_phone bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: subscriberCount bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: null_sum bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n","Binning: topFriends bin_num_limit=8 stop_limit=0.05 count_distr_limit=0.05\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-46c5d25713b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mtest_woe_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwoe_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcd1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'woe/%s/train_woe.csv'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcd1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'woe/%s/test_woe.csv'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /content/drive/My Drive/kalapa/woe/Field_18/train_woe.csv does not exist: '/content/drive/My Drive/kalapa/woe/Field_18/train_woe.csv'"]}]},{"cell_type":"code","metadata":{"id":"SRB9zbx-aHMy"},"source":["# 4. Data Spliting\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n","\n","print(\"\\n@Learning\")\n","n_folds = 5\n","seed = 2020\n","    \n","print(\"+ Data Splitting\")\n","\n","train_fe_df.label.replace(\"Good\", 0, inplace=True)\n","train_fe_df.label.replace(\"Bad\", 1, inplace=True)\n","print(f\"Stratified {n_folds}-fold, seed={seed}\")\n","y = train_fe_df[\"label\"].values\n","#cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed) ##Update\n","cv = StratifiedShufleSplit(n_splits = n_folds, test_size = 0.2) ##Updated\n","for i, (train, val) in enumerate(cv.split(np.zeros(len(y)), y)):\n","    print(\"FOLD %d\" % (i + 1))\n","    os.makedirs(os.path.join(cd1, \"fold%d\" % i), exist_ok=True)\n","    train_df, val_df = train_fe_df.loc[train], train_fe_df.loc[val]\n","    # use all positive examples for training and evaluation\n","    train_df = pd.concat([train_df, val_df[val_df.label == 1]])\n","    val_df = pd.concat([val_df, train_df[train_df.label == 1]])\n","    train_df.to_csv(os.path.join(cd1, \"fold%d/train.csv\" % i), index=False)\n","    val_df.to_csv(os.path.join(cd1, \"fold%d/val.csv\" % i), index=False)\n","\n","print(\"-\"*50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_8sttYjSaK_G"},"source":["seed = 2020\n","n_trees = 767\n","max_depth = 17\n","min_samples_split = 2\n","min_samples_leaf = 1 \n","max_features = 'auto'\n","class_weight = None\n","bootstrap = True\n","n_folds = 5\n","\n","#embeddings = pd.read_pickle(\"./data/embeddings.pkl\").to_numpy(dtype=np.float32)\n","\n","# submission input\n","X_submit = pd.read_csv(os.path.join(INPUT_DIR, \"test_fe.csv\"))\n","submit_id = X_submit.id.to_numpy(int)\n","submit_dict = {\"id\": submit_id}\n","X_submit.drop(columns=[\"id\"], inplace=True)\n","X_submit = X_submit.to_numpy(dtype=np.float32)\n","#X_submit = np.concatenate([X_submit, embeddings[submit_id]], axis=1)\n","print(X_submit.shape)\n","\n","# training and evaluation\n","tprs = []\n","aucs = []\n","mean_fpr = np.linspace(0, 1, 100)\n","\n","fold_aucs = []\n","\n","fig, ax = plt.subplots()\n","for i in range(n_folds):\n","    print(\"FOLD %d\" % (i + 1))\n","\n","    train_df = pd.read_csv(os.path.join(cd1, \"fold%d/train.csv\" % i))\n","    val_df = pd.read_csv(os.path.join(cd1, \"fold%d/val.csv\" % i))\n","    train_id = train_df.id.to_numpy(int)\n","    val_id = val_df.id.to_numpy(int)\n","    train_df.drop(columns=[\"id\"], inplace=True)\n","    val_df.drop(columns=[\"id\"], inplace=True)\n","    \n","    y_train = train_df[\"label\"].to_numpy(dtype=np.float32)\n","    X_train = train_df.drop(columns=[\"label\"]).to_numpy(dtype=np.float32)\n","    #X_train = np.concatenate([X_train, embeddings[train_id]], axis=1)\n","    y_val = val_df[\"label\"].to_numpy(dtype=np.float32)\n","    X_val = val_df.drop(columns=[\"label\"]).to_numpy(dtype=np.float32)\n","    #X_val = np.concatenate([X_val, embeddings[val_id]], axis=1)\n","    print(X_train.shape, X_val.shape)\n","\n","  \n","    clf = RandomForestClassifier(\n","        n_estimators=n_trees,\n","        max_depth=max_depth,\n","        min_samples_split=min_samples_split,\n","        min_samples_leaf=min_samples_leaf,\n","        max_features=max_features,\n","        random_state=seed,\n","        class_weight=class_weight,\n","        bootstrap=True,\n","        n_jobs=1\n","    )\n","\n","    clf.fit(X_train, y_train)\n","\n","    auc_ = roc_auc_score(y_val, clf.predict_proba(X_val)[:, 1])\n","    fold_aucs.append(auc_)\n","    print(f\"val AUC = {auc_:.4f}\")\n","\n","    y_submit = clf.predict_proba(X_submit)[:, 1]\n","    submit_dict[\"fold%d\" % i] = y_submit\n","\n","    viz = plot_roc_curve(\n","        clf, X_val, y_val, name=f\"ROC Fold {i}\", alpha=0.3, lw=1, ax=ax\n","    )\n","    interp_tpr = interp(mean_fpr, viz.fpr, viz.tpr)\n","    interp_tpr[0] = 0.0\n","    tprs.append(interp_tpr)\n","    aucs.append(viz.roc_auc)\n","\n","ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Random\", alpha=0.8)\n","\n","mean_tpr = np.mean(tprs, axis=0)\n","mean_tpr[-1] = 1.0\n","mean_auc = auc(mean_fpr, mean_tpr)\n","std_auc = np.std(aucs)\n","ax.plot(\n","    mean_fpr,\n","    mean_tpr,\n","    color=\"b\",\n","    label=r\"Mean ROC (AUC = %0.3f $\\pm$ %0.3f)\" % (mean_auc, std_auc),\n","    lw=2,\n","    alpha=0.8,\n",")\n","\n","std_tpr = np.std(tprs, axis=0)\n","tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n","tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n","ax.fill_between(\n","    mean_fpr,\n","    tprs_lower,\n","    tprs_upper,\n","    color=\"grey\",\n","    alpha=0.2,\n","    label=r\"$\\pm$ 1 std. dev.\",\n",")\n","\n","ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title=\"ROC Curves\")\n","ax.legend(loc=\"lower right\")\n","plt.savefig(\"roc.png\")\n","\n","print(\"Mean AUC = %0.4f, GINI %0.4f\" % (mean_auc, 2 * mean_auc - 1.0))\n","\n","print(\"\\t\".join(f\"{x:.4f}\" for x in fold_aucs))\n","\n","##Updated\n","#Plot important feature\n","feature_imp = pd.Series(clf.feature_importances_,index=train_fe.columns).sort_values(ascending=False)\n","%matplotlib inline\n","# Creating a bar plot\n","plt.figure(figsize = (50, 50))\n","sns.barplot(x=feature_imp.head(100), y=feature_imp.head(100).index)\n","\n","# Add labels to your graph\n","plt.xlabel('Feature Importance Score')\n","plt.ylabel('Features')\n","plt.title(\"Visualizing Important Features\")\n","#plt.legend()\n","plt.show()\n","##End\n","\n","# averaging for submission\n","res_df = pd.DataFrame(submit_dict)\n","res_df[\"label\"] = res_df[[\"fold%d\" % i for i in range(n_folds)]].mean(axis=1)\n","res_df[[\"id\", \"label\"]].to_csv(\"submission.csv\", index=False)\n","\n","for i in range(n_folds):\n","    res_df[\"label\"] = res_df[f\"fold{i}\"]\n","    res_df[[\"id\", \"label\"]].to_csv(\"submission_fold%d.csv\" % i, index=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGhpPsuWhuif","outputId":"f9b7851a-d36b-42cf-e300-b83b6a467b56","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["for i in range (0, 5):\n","  print(i)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","1\n","2\n","3\n","4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QM416RogaW_z"},"source":["print(\"\\n@Rules\")\n","\n","for i in range(0, 5):\n","    sub_df = pd.read_csv(\"submission_fold%d.csv\" % i)\n","\n","    # Smoothing\n","    y = sub_df.label.to_numpy()\n","    rank = np.argsort(y)\n","    y_smooth = np.arange(len(rank)) * (1.0 / (len(rank) - 1))\n","    y[rank] = y_smooth\n","    sub_df.label = y\n","\n","    rule_df = pd.read_csv(\"rules.csv\", dtype=str, encoding=\"utf-8\")\n","    test_df = pd.read_csv(os.path.join(cd1, \"test.csv\"), dtype=str, encoding=\"utf-8\")\n","\n","    mask = np.ones(sub_df.shape[0])\n","\n","    for col in rule_df.columns:\n","        patterns = set(str_normalize_final(v) for v in rule_df[col].unique())\n","        patterns -= set(['nan'])\n","        if len(patterns) == 0:\n","            continue\n","    \n","        col_mask = test_df[col].apply(lambda x: 0. if str_normalize_final(x) in patterns else 1.)    \n","        mask *= col_mask.to_numpy()\n","    \n","    # Smoothing\n","    y = sub_df.label.to_numpy()\n","    org_idx = np.argwhere(mask).ravel()\n","    y_masked = y[org_idx]\n","    rank = np.argsort(y_masked)\n","    y_smooth = np.arange(1, len(rank) + 1) * (1.0 / (len(rank) + 1))\n","    y_masked[rank] = y_smooth\n","    y[org_idx] = y_masked\n","\n","    sub_df.label = y * mask\n","    sub_df.to_csv(\"final_submission%d.csv\" % i, index=False)"],"execution_count":null,"outputs":[]}]}