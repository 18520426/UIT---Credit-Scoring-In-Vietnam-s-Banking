{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bản sao của kalapa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlEc63FgB3J7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a4f95779-de13-4d16-b8c8-ff9397cc1e25"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knKEjEEYIRDH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15332d0c-3416-4c4c-fbf6-2facb9a851b5"
      },
      "source": [
        "cd /content/drive/My Drive/kalapa"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/kalapa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om6YQ3fKCGec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "d870507b-ef62-43b9-cb14-3cb7f99cc090"
      },
      "source": [
        "!pip install feature_engine\n",
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: feature_engine in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (1.0.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (1.4.1)\n",
            "Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.6/dist-packages (from feature_engine) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.3->feature_engine) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.1)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.2->feature_engine) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=1.0.3->feature_engine) (1.15.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH7hco0wCZV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import combinations\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from itertools import combinations\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "import lightgbm as lgb\n",
        "from unidecode import unidecode\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from feature_engine import categorical_encoders as ce\n",
        "\n",
        "from itertools import combinations\n",
        "from datetime import datetime\n",
        "from contextlib import contextmanager"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6vLutkQCggr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgbm_param = {'boosting_type': 'gbdt', \n",
        "              'colsample_bytree': 0.6602479798930369, \n",
        "              'is_unbalance': False, \n",
        "              'learning_rate': 0.01,\n",
        "              'max_depth': 15, \n",
        "              'metric': 'auc', \n",
        "              'min_child_samples': 25, \n",
        "              'num_leaves': 100,\n",
        "              'objective': 'binary', \n",
        "              'reg_alpha': 0.4693391197064131, \n",
        "              'reg_lambda': 0.16175478669541327, \n",
        "              'subsample_for_bin': 70000}\n",
        "\n",
        "NUM_BOOST_ROUND= 10000\n",
        "\n",
        "DROP = [\"gioiTinh\",\"info_social_sex\", 'currentLocationCity', 'currentLocationName', 'homeTownCity', 'homeTownName'] + [f\"Field_{c}\" for c in [11, 14, 15, 16, 17, 18, 24,25, 26, 30, 31, 32, 33, 34,35, 37,40,45, 46, 48,49, 52, 56, 57, 68]]\n",
        "DATE = [\"Field_{}\".format(i) for i in [5, 6, 7, 8, 9, 11, 15, 25, 32, 33, 34, 35, 40]]\n",
        "DATETIME = [\"Field_{}\".format(i) for i in [1, 2, 43, 44]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azUNtp6OCuSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def timer(title):\n",
        "    t0 = time.time()\n",
        "    yield\n",
        "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
        "\n",
        "def Gini(y_true, y_pred):\n",
        "    # check and get number of samples\n",
        "    assert y_true.shape == y_pred.shape\n",
        "    n_samples = y_true.shape[0]\n",
        "\n",
        "    # sort rows on prediction column\n",
        "    # (from largest to smallest)\n",
        "    arr = np.array([y_true, y_pred]).transpose()\n",
        "    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n",
        "    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n",
        "\n",
        "    # get Lorenz curves\n",
        "    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n",
        "    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n",
        "    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n",
        "\n",
        "    # get Gini coefficients (area between curves)\n",
        "    G_true = np.sum(L_ones - L_true)\n",
        "    G_pred = np.sum(L_ones - L_pred)\n",
        "\n",
        "    # normalize to true Gini coefficient\n",
        "    return G_pred * 1. / G_true\n",
        "\n",
        "def lgb_gini(y_pred, dataset_true):\n",
        "    y_true = dataset_true.get_label()\n",
        "    return 'gini', Gini(y_true, y_pred), True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCUl1Rz1C48M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def subtract_date(date1,date2, df):\n",
        "    df[date1] = pd.to_datetime(df[date1], infer_datetime_format=True)\n",
        "    df[date2] = pd.to_datetime(df[date2], infer_datetime_format=True)\n",
        "    df[date1+date2] = (df[date2] - df[date1]).dt.days\n",
        "    \n",
        "def process_ngaySinh(s):\n",
        "    if s != s:\n",
        "        return np.nan\n",
        "    try:\n",
        "        s = int(s)\n",
        "    except ValueError:\n",
        "        s = s.split(\" \")[0]\n",
        "        \n",
        "    return datetime.strptime(str(s)[:6], \"%Y%m\")\n",
        "\n",
        "def datetime_normalize(s):\n",
        "    if s != s:\n",
        "        return np.nan\n",
        "    s = s.split(\".\")[0]\n",
        "    if s[-1] == \"Z\":\n",
        "        s = s[:-1]\n",
        "        \n",
        "    date, time = s.split(\"T\")\n",
        "    datetime_obj = datetime.strptime(s, \"%Y-%m-%dT%H:%M:%S\")\n",
        "    return datetime_obj\n",
        "\n",
        "def date_normalize(s):\n",
        "    if s != s:\n",
        "        return np.nan\n",
        "    \n",
        "    try:\n",
        "        datetime_obj = datetime.strptime(s, \"%m/%d/%Y\")\n",
        "    except:\n",
        "        datetime_obj = datetime.strptime(s, \"%Y-%m-%d\")\n",
        "        \n",
        "    return datetime_obj\n",
        "  \n",
        "def process_datetime_cols(df):\n",
        "    cat_cols = []\n",
        "    for col in DATETIME:\n",
        "        df[col] = df[col].apply(datetime_normalize)\n",
        "        \n",
        "    for col in DATE:\n",
        "        if col == \"Field_34\":\n",
        "            continue\n",
        "        df[col] = df[col].apply(date_normalize)\n",
        "\n",
        "    df[\"Field_34\"] = df[\"Field_34\"].apply(process_ngaySinh)\n",
        "    df[\"ngaySinh\"] = df[\"ngaySinh\"].apply(process_ngaySinh)\n",
        "    \n",
        "    cat_cols += DATE + DATETIME\n",
        "    for col in DATE + DATETIME:\n",
        "        #df[col].fillna(0)\n",
        "        df[col] = df[col].dt.strftime('%d-%m-%Y')\n",
        "    \n",
        "    subtract_date('Field_5','Field_6',df)\n",
        "    subtrac_List = ['Field_1', 'Field_2', 'Field_43', 'Field_44', 'Field_7','Field_8', 'Field_9']\n",
        "    subtract_2C = list(combinations(subtrac_List, 2))\n",
        "    for l in subtract_2C:\n",
        "        subtract_date(l[0],l[1],df)\n",
        "      \n",
        "    for cat in ['F', 'E', 'C', 'G', 'A']:\n",
        "        subtract_date(f'{cat}_startDate', f'{cat}_endDate', df)\n",
        "    print(df.shape) \n",
        "    return df\n",
        "  \n",
        "def str_normalize(s):\n",
        "    s = str(s).strip().lower()\n",
        "    s = re.sub(' +', \" \", s)\n",
        "    return s\n",
        "\n",
        "def process_location(df):\n",
        "    for col in [\"currentLocationLocationId\", \"homeTownLocationId\", \"currentLocationLatitude\", \"currentLocationLongitude\", \n",
        "                   \"homeTownLatitude\", \"homeTownLongitude\"]:\n",
        "        df[col].replace(0, np.nan, inplace=True)\n",
        "\n",
        "#     df[\"currentLocationLocationId\"] = df[\"currentLocationLocationId\"].apply(str_normalize).astype(\"category\")\n",
        "#     df[\"homeTownLocationId\"] = df[\"homeTownLocationId\"].apply(str_normalize).astype(\"category\")\n",
        "\n",
        "    return df\n",
        "\n",
        "    \n",
        "def combine_gender(s):\n",
        "    x, y = s\n",
        "    return x if x != None else y if y != None else None\n",
        "\n",
        "def process_gender(df):\n",
        "    df[\"gender\"] = df[[\"gioiTinh\", \"info_social_sex\"]].apply(combine_gender, axis=1).astype(\"category\")\n",
        "    return df\n",
        "\n",
        "def process_ordinal(df):        \n",
        "    df[\"subscriberCount\"].replace(0, np.nan, inplace=True)\n",
        "    df[\"friendCount\"].replace(0, np.nan, inplace=True)\n",
        "    \n",
        "    df[\"Field_13\"] = df[\"Field_13\"].apply(lambda x: 1 if x == x else 0)\n",
        "    df[\"Field_38\"] = df[\"Field_38\"].map({0: 0.0, 1: 1.0, \"DN\": np.nan, \"TN\": np.nan, \"GD\": np.nan})\n",
        "    df[\"Field_62\"] = df[\"Field_62\"].map({\"I\": 1, \"II\": 2, \"III\": 3, \"IV\": 4, \"V\": 5, \"Ngoài quốc doanh Quận 7\": np.nan})\n",
        "    df[\"Field_47\"] = df[\"Field_47\"].map({\"Zezo\": 0, \"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4})\n",
        "    \n",
        "    df[\"Field_27\"] = df[\"Field_27\"].replace({0.0: np.nan})\n",
        "    df[\"Field_28\"] = df[\"Field_28\"].replace({0.0: np.nan})\n",
        "        \n",
        "    for col in df.columns:\n",
        "        if df[col].dtype.name == \"object\":\n",
        "            df[col] = df[col].apply(str_normalize).astype(\"category\")\n",
        "            \n",
        "    return df\n",
        "\n",
        "def transform(df):\n",
        "    df = process_datetime_cols(df)\n",
        "    df = process_gender(df)\n",
        "    df = process_location(df)\n",
        "    df = process_ordinal(df)\n",
        "    df[\"null_sum\"] = df.isnull().sum(axis=1)\n",
        "    return df.drop(DROP, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTrcMBbhMJqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kfold(train_fe,y_label,test_fe):\n",
        "    seeds = np.random.randint(0, 10000, 1)\n",
        "    preds = 0    \n",
        "    feature_important = None\n",
        "    avg_train_gini = 0\n",
        "    avg_val_gini = 0\n",
        "\n",
        "    for s in seeds:\n",
        "        skf = StratifiedKFold(n_splits=5, random_state = 6484, shuffle=True)        \n",
        "        lgbm_param['random_state'] = 6484    \n",
        "        seed_train_gini = 0\n",
        "        seed_val_gini = 0\n",
        "        for i, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(y_label)), y_label)):                \n",
        "            X_train, X_val = train_fe.iloc[train_idx].drop([\"id\"], 1), train_fe.iloc[val_idx].drop([\"id\"], 1)                \n",
        "            y_train, y_val = y_label[train_idx], y_label[val_idx]\n",
        "\n",
        "            lgb_train = lgb.Dataset(X_train, y_train)\n",
        "            lgb_eval  = lgb.Dataset(X_val, y_val)\n",
        "\n",
        "            evals_result = {}\n",
        "            model = lgb.train(lgbm_param,\n",
        "                        lgb_train,\n",
        "                        num_boost_round=NUM_BOOST_ROUND,  \n",
        "                        early_stopping_rounds=400,\n",
        "                        feval=lgb_gini,\n",
        "                        verbose_eval= 200,\n",
        "                        evals_result=evals_result,\n",
        "                        valid_sets=[lgb_train, lgb_eval])\n",
        "\n",
        "            seed_train_gini += model.best_score[\"training\"][\"gini\"] / skf.n_splits\n",
        "            seed_val_gini += model.best_score[\"valid_1\"][\"gini\"] / skf.n_splits\n",
        "\n",
        "            avg_train_gini += model.best_score[\"training\"][\"gini\"] / (len(seeds) * skf.n_splits)\n",
        "            avg_val_gini += model.best_score[\"valid_1\"][\"gini\"] / (len(seeds) * skf.n_splits)\n",
        "\n",
        "            if feature_important is None:\n",
        "                feature_important = model.feature_importance() / (len(seeds) * skf.n_splits)\n",
        "            else:\n",
        "                feature_important += model.feature_importance() / (len(seeds) * skf.n_splits)        \n",
        "\n",
        "            pred = model.predict(test_fe.drop([\"id\"], 1))\n",
        "            preds += pred / (skf.n_splits * len(seeds))\n",
        "\n",
        "            print(\"Fold {}: {}/{}\".format(i, model.best_score[\"training\"][\"gini\"], model.best_score[\"valid_1\"][\"gini\"]))\n",
        "        \n",
        "        print(\"Seed {}: {}/{}\".format(s, seed_train_gini, seed_val_gini))\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(\"Avg train gini: {}\".format(avg_train_gini))\n",
        "    print(\"Avg valid gini: {}\".format(avg_val_gini))\n",
        "    print(\"=\" * 50)\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6sRAY-xDih1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    df_train = pd.read_csv('/content/drive/My Drive/kalapa/dataset/train3.csv')\n",
        "    df_test = pd.read_csv('/content/drive/My Drive/kalapa/dataset/test.csv')\n",
        "    for col in DATE + DATETIME:\n",
        "        df_train[col].fillna(0)\n",
        "        df_test[col].fillna(0)\n",
        "    df_all = df_train.drop(['label'], 1).append(df_test)\n",
        "    #df_train.fillna(-1, inplace=True)\n",
        "    #df_test.fillna(-1, inplace=True)\n",
        "    #df_train = df_train.replace([np.inf, -np.inf], np.nan).dropna(axis=0,inplace = True)\n",
        "    #df_test = df_test.replace([np.inf, -np.inf], np.nan).dropna(axis=0, inplace = True)\n",
        "\n",
        "    \n",
        "    \n",
        "    with timer(\"Preprocess\"):\n",
        "        df_all_fe = transform(df_all.copy())\n",
        "        print(\"Bureau df shape:\", df_all_fe.shape)\n",
        "        df_all_fe['Age'] = df_all_fe.ngaySinh.apply(lambda x: 2020 - x.year)\n",
        "        df_all_fe = df_all_fe.drop('ngaySinh', axis = 1)\n",
        "        cols_select = [x for x in df_all_fe.columns if x not in DATE + DATETIME  + [f'{cat}_endDate' for cat in ['F', 'E', 'C', 'G', 'A']] + [f'{cat}_startDate' for cat in ['F', 'E', 'C', 'G', 'A']]]\n",
        "        df_fe = df_all_fe[cols_select]\n",
        "        df_fe.replace([np.inf, -np.inf], -99999, inplace=True)\n",
        "\n",
        "        y_label = df_train[\"label\"]\n",
        "        train_fe = df_fe[df_fe[\"id\"] < df_train.shape[0]]\n",
        "        test_fe = df_fe[df_fe[\"id\"] >= df_train.shape[0]]\n",
        "\n",
        "        # Label-Encoding\n",
        "        lbl = LabelEncoder()\n",
        "        for col in df_fe.columns:\n",
        "          if df_fe[col].dtype.name == \"category\":\n",
        "            train_fe[col] = train_fe[col].astype(str)\n",
        "            test_fe[col] = test_fe[col].astype(str)\n",
        "            encoder = ce.CountFrequencyCategoricalEncoder(encoding_method='frequency')\n",
        "            train_fe[col] = train_fe[col].fillna('None')\n",
        "            test_fe[col] = test_fe[col].fillna('None')\n",
        "\n",
        "            # Only take the common values in Train/Test set\n",
        "            common_vals = list(set(train_fe[col]).intersection(set(test_fe[col])))\n",
        "\n",
        "            # Take if vals appeared both 5 times\n",
        "            common_vals = set(train_fe[col].value_counts()[train_fe[col].value_counts() > 4].index).intersection(test_fe[col].value_counts()[test_fe[col].value_counts()>4].index)\n",
        "\n",
        "            # Replace not-common values with \"Missing\" or np.nan\n",
        "            train_fe.loc[~train_fe[col].isin(common_vals), col] = 'Missing'\n",
        "            test_fe.loc[~test_fe[col].isin(common_vals), col] = 'Missing'\n",
        "\n",
        "            # Implement LE\n",
        "            lbl.fit(train_fe[col].tolist() + test_fe[col].tolist())\n",
        "            train_fe[col] = lbl.transform(train_fe[col])\n",
        "            test_fe[col] = lbl.transform(test_fe[col])\n",
        "\n",
        "        print(train_fe.shape)\n",
        "        print(test_fe.shape)\n",
        "    with timer(\"Kfold\"):\n",
        "        preds = kfold(train_fe,y_label,test_fe)\n",
        "        df_test[\"label\"] = preds\n",
        "        df_test[['id', 'label']].to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL5ZSvP7EKGE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "51420374-3f11-4bb1-91a0-1abd7e456b8e"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    submission_file_name = \"submission.csv\"\n",
        "    \n",
        "    with timer(\"Full model run\"):\n",
        "        main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (2,3,5,6,7,8,9,10,12,16,19,26,33,34,35,36,39,40,41,45,48,49,50,51,53,54,59,60,61,66,67,73,74,85,93,94,95,96,97,98,99,100,101,106,107,110,111,114,115,118,119,122,123,188) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (34,42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1068956, 221)\n",
            "Bureau df shape: (1068956, 192)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4172: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(73411, 173)\n",
            "(0, 173)\n",
            "Preprocess - done in 127s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-620b163d4be6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Full model run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-808b2c80c81d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_fe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Kfold\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_fe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_fe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-4054ce635c8f>\u001b[0m in \u001b[0;36mkfold\u001b[0;34m(train_fe, y_label, test_fe)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mseed_train_gini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mseed_val_gini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_fe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \"\"\"\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MOo-yN7QN8J",
        "colab_type": "text"
      },
      "source": [
        "0.5072735159107776"
      ]
    }
  ]
}